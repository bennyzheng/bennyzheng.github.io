<?xml version="1.0" encoding="utf-8"?>
<search>
  
    
    <entry>
      <title><![CDATA[如何降低try-catch对性能的影响]]></title>
      <url>%2Farchivers%2F2016%2F12%2Ftry-catch%2F</url>
      <content type="text"><![CDATA[一直都知道try-catch对代码运行速度会有影响，今天刚好有这方面的尝试，于是试验了一下，试验场景是： 不使用try-catch try-catch内部费时代码是否放到函数中时性能区别 直接将费时代码放在try-catch中 将费时代码放入内置函数中 将费时代码放到外部函数中进行调用 try-catch内部是否引用外部变量时性能区别 引用外部变量 不引用外部变量 try-catch是否放在子作用域时性能区别 放在子作用域 不放在子作用域 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143// 执行99999999次的取模var time = 99999999;// 不使用try-catchfunction test1() &#123; var value = 0; var obj = &#123;&#125;; console.time("test1"); for (var i = 0; i &lt; time; i++) &#123; value = i % 5; &#125; console.timeEnd("test1");&#125;// try-catch内部有无费时代码时性能区别// 直接将费时代码放在try-catch中function test2() &#123; var value = 0; var obj = &#123;&#125;; console.time("test2"); try &#123; for (var i = 0; i &lt; time; i++) &#123; value = i % 5; &#125; &#125;catch(ex)&#123;&#125; console.timeEnd("test2");&#125;// try-catch内部有无费时代码时性能区别// 将费时代码放入内置函数中function test3() &#123; var value = 0; var obj = &#123;&#125;; console.time("test3"); try &#123; (function() &#123; for (var i = 0; i &lt; time; i++) &#123; value = i % 5; &#125; obj.value = value; &#125;)(); &#125;catch(ex)&#123;&#125; console.timeEnd("test3");&#125;// try-catch内部有无费时代码时性能区别// 将费时代码放到外部函数中进行调用function test4() &#123; var value = 0; var obj = &#123;&#125;; console.time("test4"); function fn() &#123; for (var i = 0; i &lt; time; i++) &#123; value = i % 5; &#125; obj.value = value; &#125; try &#123; fn(); &#125;catch(ex)&#123;&#125; console.timeEnd("test4");&#125;// try-catch内部是否引用外部变量时性能区别// 引用外部变量function test5() &#123; var value = 0; var obj = &#123;&#125;; console.time("test5"); for (var i = 0; i &lt; time; i++) &#123; value = i % 5; &#125; try &#123; obj.value = value; &#125;catch(ex)&#123;&#125; console.timeEnd("test5");&#125;// try-catch内部是否引用外部变量时性能区别// 不引用外部变量// 以及// try-catch是否放在子作用域时性能区别// 不放在子作用域function test6() &#123; var value = 0; var obj = &#123;&#125;; console.time("test6"); for (var i = 0; i &lt; time; i++) &#123; value = i % 5; &#125; obj.value = value; try &#123; &#125;catch(ex)&#123;&#125; console.timeEnd("test6");&#125;// try-catch是否放在子作用域时性能区别// 放在子作用域function test7() &#123; var value = 0; var obj = &#123;&#125;; console.time("test7"); for (var i = 0; i &lt; time; i++) &#123; value = i % 5; &#125; obj.value = value; (function() &#123; try &#123; &#125;catch(ex)&#123;&#125; &#125;)(); console.timeEnd("test7");&#125;test1();test2();test3();test4();test5();test6();test7(); 在我的机子上运行多次后得出类似这样的结果： 1234567test1: 49.595mstest2: 345.197mstest3: 213.598mstest4: 182.665mstest5: 441.871mstest6: 449.331mstest7: 155.332ms 基本上可以得出初步结论： 尽量不使用try-catch，性能确实影响相当大 try-catch内部代码尽可能使用外部函数调用 try-catch应该使用函数包起来，对性能提升明显 在这里还有个疑问，如果try-catch使用函数包起来之后还引用了外部变量，那么它的表现如何？改一下test7的代码试试： 12345678910111213141516171819// try-catch是否放在子作用域时性能区别// 放在子作用域并引用外部变量function test8() &#123; var value = 0; var obj = &#123;&#125;; console.time("test8"); for (var i = 0; i &lt; time; i++) &#123; value = i % 5; &#125; (function() &#123; try &#123; obj.value = value; &#125;catch(ex)&#123;&#125; &#125;)(); console.timeEnd("test8");&#125; 增加了test8，再次运行之后结果如下： 12345678test1: 44.163mstest2: 355.606mstest3: 205.943mstest4: 176.373mstest5: 430.764mstest6: 462.929mstest7: 156.136mstest8: 181.711ms 结果显示确实是有影响，所以要尽量保持里边环境的纯净。 可以看出，如果引用了外部变量性能确实还是会降低。 另外，有个现象我实在解释不清，将test7再改改，把obj.value = value;那行去掉，变成test9运行结果如下： 123456789test1: 52.285mstest2: 348.937mstest3: 206.904mstest4: 185.531mstest5: 440.402mstest6: 443.279mstest7: 158.451mstest8: 181.181mstest9: 50.711ms 这什么情况啊！！！！！！！！！！！！！谁知道请告知。 本页测试代码请查阅这里。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Node.js - 进程学习笔记]]></title>
      <url>%2Farchivers%2F2016%2F12%2Fnode-process%2F</url>
      <content type="text"><![CDATA[我一直都是在浏览器端工作，算是个很普通的Web前端开发工程师，对于进程、线程方面的知识仅限于知识广度需要初步理解，但并没有真正去使用它。 使用Javascript写应用程序的例子不少，在Windows下可以用Javascript调用系统COM组件读写文件甚至写病毒；在ASP大家默认使用VBScript编写代码，同时也可以使用Javascript。Node.js是做得最好的一个，它让Javascript的世界变得更加丰富多彩，它是专门为Javascript搭建的舞台。 Node.js可以非常方便地编写一个应用程序，但要让它很高效地跑起来，几行代码是不足的，对进程和线程不理解也是不成的。我对这方面很感兴趣，但对应用程序是陌生的，思考过怎么学习，想来想去对着手册一点一点理解下去是最简单的。 process是Node.js提供给用户与当前进程交互的全局对象，你可以在任何地方使用它而不需要require任何模块。process是emitEvent的一个实例，意味着它拥有事件机制。我发现Node.js是个类都是emitEvent的子类，是个对象都是emitEvent的实例，毕竟Node.js许多东西都建立在事件驱动的理念上，同时也意味着在Node.js使用费时的同步操作基本上是个愚蠢的做法。 child_process模块则是Node.js提供给父进程使用的模块，想要学习进程相关的操作，process对象与child_process模块都是得一起研究的。 生命周期一个进程拥有五种状态，在运行期间总会处于其中的一种，并且在各种状态之间互相转换。 创建状态 - 当运行一个应用程序的时候，它并不是直接就开始运行，系统需要将它的必要信息读入内存，为其分配各种资源比如堆栈、代码区，这个初始化的过程被称为创建状态。 就绪状态 - 当一个应用程序所有资源都处于就绪状态，但由于CPU正在为其它应用程序服务时，它就处于就绪状态。当CPU空闲下来，有资源为该进程提供服务时，就绪状态就会结束进入运行状态。 运行状态 - 应用程序所有资源都就绪，并且CPU分配资源为它做计算时称为运行状态。 阻塞状态 - 应用程序可能由于某个资源未就绪而无法继续运行时就是阻塞状态，这个资源不包括CPU资源（否则就是就绪状态了）。这种状态下应用程序很可能在等待一个系统信号，比如一个socket连接。一个最简单的Web服务器在监听端口但没请求进来的时候就应该处于这种阻塞状态，它不退出，但也不占用CPU资源。阻塞状态如果由于资源到位（比如接收到一个信号），这时候就重新进入就绪状态，等到CPU资源到位进入运行状态。 退出状态 - 当应用程序由于没有任何需要处理的任务或者接收到退出信号时，系统将会将应用程序置为退出状态，为它释放各种资源，从内存中删除。 输入与输出Javascript在许多宿主环境中由于安全限制没有得到文件读写权限，也没有标准的输入输出，但在Node.js中运行则不一样，这真正是个应用程序，因此可以像其它编程语言一般访问到标准输入输出设备。 标准IO设备其实就是三个启动应用程序时就默认打开的文件： process.stdin - 标准输入设备，类型是ReadStream，默认对应键盘输入，文件描述符为0。 process.stdout - 标准输出设备，类型是WriteStream，默认对应屏幕，文件描述符为1。 process.stderr - 标准错误设备，类型是WriteStream，默认对应屏幕，文件描述符为2。 标准IO设备允许进行重定向： 1234567891011121314151617181920# 将标准输入重定向到filenamenode test.js &lt; filename# 将标准输出重定向到filenamenode test.js &gt; filename# 将标准输出重定向到filename，仅追加node test.js &gt;&gt; filename# 将标准输出重定向到filenamenode test.js 2&gt; filename# 将标准错误重定向到filename，仅追加node test.js 2&gt;&gt; filename# 将标准错误重定向到标准输出node test.js 2&gt;&amp;1# 将标准输出关闭(POSIX)node test.js &gt; /dev/null 除了标准IO设备之外，Node.js还提供了警告相关的功能，可以通过process.emitWarning输出一个警告信息，同时也可以为进程绑定warning事件用于监听该警告。 12345process.on("warning", function(ev) &#123; console.log(ev);&#125;);process.emitWarning("this is warning"); 这段代码将在控制台输出类似这样的内容： 123456789101112(node:1330) Warning: this is warning&#123; Warning: this is warning at Object.&lt;anonymous&gt; (/wwwroot/github/bennyzheng.github.io.src/test.js:5:9) at Module._compile (module.js:573:32) at Object.Module._extensions..js (module.js:582:10) at Module.load (module.js:490:32) at tryModuleLoad (module.js:449:12) at Function.Module._load (module.js:441:3) at Module.runMain (module.js:607:10) at run (bootstrap_node.js:382:7) at startup (bootstrap_node.js:137:9) at bootstrap_node.js:497:3 name: &apos;Warning&apos; &#125; 其中第一行是emitWarning函数调用输出的，而在warning事件响应中把事件对象输出则会将警告的详细调用堆栈信息输出。要特别注意的是emitWarning输出的内容是输出到stderr设备中，console.log则是将内容输出到stdout。 异常处理Node.js环境下的应用程序在默认情况下如果发生错误将会马上报错并且退出程序，一般来说可以通过try-catch来捕获错误: 1234567setTimeout(function()&#123;&#125;, 5000);try &#123; throw new Error("my error");&#125;catch(ex) &#123; console.log(ex.message);&#125; try-catch会将异常捕获，并且把ex当参数传给catch代码块，可以在里边做异常处理。当然，如果有需要，在catch代码块中对异常做完处理之后也可以再使用throw抛出错误。 try-catch对性能是相当有影响的，使用时需要将它放到一个尽可能小的作用域下以减少这种影响： 1234567891011121314151617function test() &#123; var value = 0; var obj = &#123;&#125;; console.time("test"); for (var i = 0; i &lt; time; i++) &#123; value = i % 2; &#125; (function(value) &#123; try &#123; obj.value = value; &#125; catch(ex)&#123;&#125; &#125;)(value, obj); console.timeEnd("test");&#125; 除了try-catch，进程对象还提供了uncaughtException事件用于捕获未使用try-catch捕获的异常并对其做统一处理： 1234567setTimeout(function()&#123;&#125;, 5000);process.on("uncaughtException", function(ev) &#123; console.error('报错了');&#125;);throw new Error("error"); 除了uncaughtException还有另一个事件unhandledRejection也极其类似，它与uncaughtException不同的是uncaughtException用于捕获同步代码抛出的异常，而unhandledRejection用于捕获Promise代码中的异常。 12345678910111213process.on("unhandledRejection", function() &#123; // 控制台将会输出unhandledRejection console.error("unhandledRejection");&#125;);process.on("uncaughtException", function() &#123; // 不会输出，因为不会到这来 console.error("uncaughtException");&#125;);var promise = new Promise(function(resolve, reject) &#123; throw new Error("promise err");&#125;); 由于Promise是异步的，在某一步异步处理中抛出异常将会触发unhandledRejection事件，但如果在触发unhandledRejection之后又使用catch方法捕获Promise抛出的异常（也就是出现了没及时处理的promise异常），这时候异常会被catch方法捕获并且同时触发rejectionHandled事件。 123456789101112131415161718192021process.on("unhandledRejection", function() &#123; console.error("unhandledRejection");&#125;);process.on("rejectionHandled", function() &#123; console.error("rejectionHandled");&#125;);process.on("uncaughtException", function() &#123; console.error("uncaughtException");&#125;);var promise = new Promise(function(resolve, reject) &#123; throw new Error("promise err");&#125;);setTimeout(function() &#123; promise.catch(function(err) &#123; console.log("迟来的Promise捕获"); &#125;);&#125;, 1000); 输出结果为： 123unhandledRejectionrejectionHandled迟来的Promise捕获 要特别注意的是当异常未被捕获，该进程会退出，进程的异常退出不会影响父进程但会影响子进程。如果子进程异常退出，将会于stderr输出错误信息并退出，父进程将收到子进程退出的消息；如果父进程异常退出，那么所有子进程将会被中断并且退出，除非子进程是一个独立进程（查阅options.detached）。 123456789101112const cluster = require('cluster');if (cluster.isMaster) &#123; cluster.fork(); setTimeout(function() &#123; // 虽然子进程退出了，但主进程依然于5秒后输出Ok，它不受影响 console.log("Ok"); &#125;, 5000);&#125; else &#123; throw new Error("child exit!");&#125; 123456789101112131415const cluster = require('cluster');if (cluster.isMaster) &#123; cluster.fork(); setTimeout(function() &#123; // 1秒后主进程退出 throw new Error("master exit!"); &#125;, 1000);&#125; else &#123; setTimeout(function() &#123; // 由于父进程的退出，子进程不会再输出Ok，因为它也退出了。 console.log("Ok"); &#125;, 5000);&#125; 退出处理当一个Node.js应用程序在没有任何需要处理的任务时将会退出运行，但也可以主动调用process对象的exit方法退出程序，同时指定退出时的状态代码。状态代码默认为0，表示程序是正常退出，非0则表示异常退出，调用该应用程序的父进程（或控制台）可以获取到该退出状态代码的值以做其它处理。 123456setTimeout(function() &#123; // 由于exit的调用，导致这里不会被执行。 console.log("ok");&#125;, 1000);process.exit(); exit方法一般来说不应该被调用，它会要求应用程序以最快的方式停止程序的运行，这会导致事件循环中的任务不再被处理，同时可能会导致数据丢失，比如stdout与stderr输出一半就停止。建议在没有把握的情况下不要调用exit方法，如果需要设置退出状态码可以为process.exitCode赋值： 1234567setTimeout(function() &#123; console.log("ok");&#125;, 1000);// 不要这么干// process.exit();process.exitCode = -1; 当应用程序退出时将会触发process对象的exit事件，但请不要在exit事件里做异步调用，绑定该事件不会等待事件循环清空再退出应用程序。 1234567process.on("exit", function() &#123; console.log("exit!"); setTimeout(function() &#123; console.log("这句代码不会被执行！"); &#125;, 1000);&#125;); 如果希望在应用程序退出之前做异步操作那么可以使用beforeExit事件，它允许在事件响应函数中为事件循环添加新的任务，并且中止退出操作。但需要注意的是，如果使用的是exit方法退出应用程序，那么它不会被触发，必须是由于事件循环中没有任何任务而自然退出的情况才会触发beforeExit事件： 1234567process.on("beforeExit", function() &#123; console.log("exit!"); setTimeout(function() &#123; console.log("beforeExit"); &#125;, 1000);&#125;); 上边这个示例的beforeExit事件响应函数使用setTimeout为事件循环添加了一个任务，导致应用程序中止退出，并且正常情况下应用程序永远都不会退出成功，因为每次要退出都会触发beforeExit事件并被中止。因此使用beforeExit事件时一定要注意不要形成死循环，导致应用程序无法退出。 12345678910process.on("beforeExit", function() &#123; console.log("exit!"); setTimeout(function() &#123; console.log("beforeExit"); // 使用exit方法就不会触发beforeExit形成死循环了 // 但这依然不是真正安全的，比如还有数据没被写到磁盘导致数据丢失。 process.exit(0); &#125;, 1000);&#125;); 主动退出应用程序还有另一个与exit类似的方法abort，它表示中断程序运行，同时会给出一个核心文件内容以供开发者分析。 延迟执行任务在写代码时有时候有些任务不需要同步执行，可以使用setTimeout(xxx, 0)来做延迟执行，但Node.js提供了更有效率的方法：process.nextTick。 Node.js的事件循环队列其实可以简单理解成一个数组（当然真实情况没这么简单），每个元素是一个函数，它代表着一个需要被执行的任务。process会取出该数组然后做一次遍历，将每个函数执行一次。当process.nextTick被调用时，任务会被添加到数组的末尾，在它之前的任务全部执行完之后才会执行。 123456789101112131415setTimeout(function() &#123; console.log("1秒")&#125;, 1000);setTimeout(function() &#123; console.log("2秒");&#125;, 2000);console.log("我要输出1");process.nextTick(function() &#123; console.log("什么时候输出？");&#125;);console.log("我要输出2"); 输出结果为： 12345我要输出1我要输出2什么时候输出？1秒2秒 从这里可以看出，text.js的主体代码是一个任务，”我要输出1”以及”我要输出2”最先被执行，然后执行nextTick注册的任务。setTimeout注册的任务并不会马上被执行，它并不在事件循环中，使用的是Javascript内部的任务队列。 参数处理进程对象提供了几个属性用于读取进程的参数信息： process.argv argv包含所有参数的数组，它的第一个元素是node.js可执行文件的路径，第二个元素是当前进程文件的路径，后边再接着传给本进程的各种参数，以空格分隔。 1console.log(process.argv); 运行”node test.js –help”之后输出结果是： 123[ &apos;/usr/local/bin/node&apos;, &apos;/wwwroot/github/bennyzheng.github.io.src/test.js&apos;, &apos;--help&apos; ] process对象还提供了argv0属性方便我们获取第一个参数（有这必要么……），不过argv0存储的是参数的原始值，比如”node test.js”，它的值不是’/usr/local/bin/node’，而是’node’。 在启动进程的时候我们往往是使用node命令指定脚本文件启动，这时候可能会给node传参数，这些参数可以使用execArgv获取到： 1console.log(process.execArgv); 执行”node -i test.js”运行结果如下： 1[ &apos;-i&apos; ] PS:建议使用argv模块来处理参数相关的事务，它可以在npmjs站点的argv相关页面获取，使用npm install argv安装。 子进程建立子进程建立一个子进程相当于执行磁盘上的某个可执行文件，把该可执行文件建立起来的进程当做当前进程的子进程。 exec(command[, options][, callback]) execSync(command[, options]) 启动一个shell运行一段命令，由于是shell执行因此可以做很多复杂的事情比如建立管道、输入输出流重定向。 12345678910111213// test.jsvar child_process = require("child_process");child_process.exec("./test.sh", function(error, stdout, stderr) &#123; // 如果test.sh没有可执行权限则会报权限不足 // chmod u+x ./test.sh if (error) &#123; console.error(stderr); return; &#125; console.log(stdout);&#125;); 12# test.shecho 'hello' execFile(file[, args][, options][, callback]) execFileSync(file[, args][, options]) execFile与exec比较接近，但它不会启动一个shell来解析命令，因此它无法建立管道、重定向IO。由于不会新建shell，因此相对exec来说execFile更高效。 123456789101112var child_process = require("child_process");child_process.execFile("./test.sh", function(error, stdout, stderr) &#123; // 如果test.sh没有可执行权限则会报权限不足 // chmod u+x ./test.sh if (error) &#123; console.error(stderr); return; &#125; console.log(stdout);&#125;); 要特别注意的是，据称windows下如果没有shell则无法运行.bat之类的shell脚本（未实测，哥没win系统），也就是execFile无法用于运行.bat脚本，但可以这么写（我个人觉得没必要，还不如直接使用exec方法）： 12345678910var child_process = require("child_process");child_process.execFile('cmd.exe', ["./test.sh"], function(error, stdout, stderr) &#123; if (error) &#123; console.error(stderr); return; &#125; console.log(stdout);&#125;); spawn(command[, args][, options]) spawnSync(command[, args][, options]) spawn默认不会新建shell，但你可以将options的shell选项设置为true或者设置为某个shell的地址启用shell，在这方面算是比较自由。但这并不是spawn与exec区别最大的地方，exec/execFile会将命令执行完再将stdout/stderr的内容当成参数传递给回调函数，它们能够传递的内容比较有限，在没更改options的设置值的情况下是200KB的缓冲区，如果产生的内容超出200KB则会报错。spawn则可以通过stdout/stderr流来获取数据，比如调用curl下载远程文件并保存内容。 123456789101112var child_process = require("child_process");var child = child_process.spawn("./test.sh");// hellochild.stdout.on("data", function(chunk) &#123; console.log(chunk.toString());&#125;);// 如果test.sh没有可执行权限，则会报EACCESS错误child.stderr.on("data", function(chunk) &#123; console.error(chunk.toString());&#125;); child_process.fork(modulePath[, args][, options]) fork一个有Node.js特色的建立子进程的方式，它允许指定一个js文件作为启动代码在Node.js环境下执行，这是spawn方法的特殊应用场景，子进程将与父进程建立IPC通道用于进程通讯，而fork方法返回的子进程对象的stdio将不会被赋值，父进程与子进程将以IPC通道进行通讯。 1234567// test.jsvar child_process = require("child_process");var child = child_process.fork("./child.js");child.on("message", function(message) &#123; console.log("message: %s", message);&#125;); 12// child.jsprocess.send("this is child!"); 要注意的是fork是不能通过child.stdout来获取数据的，子进程与父进程是通过IPC通道进行通讯。另外，fork它并不是将当前进程复制一份作为子进程（其它语言都是这么干的），而是指定一个模块建立一个子进程。 子进程输入输出建立子进程时可以通过设置options参数的stdio指定子进程使用的IO，它的值只可以是一个字符串用于一次性为子进程指定输入输出流也可以使用数组分开为stdin/stdout/stderr指定值，这个参数也是父进程与子进程进行通讯的重要基础。 pipe - 流管道默认值，相当于[‘pipe’, ‘pipe’, ‘pipe’]，它会将ChildProcess的输入当成子进程的输入的管道上流，同时将ChildProcess进程的输出当成子进程输出的管道下流。 123456789101112// test.jsvar child_process = require("child_process");var child = child_process.spawn("node", ['./child.js'], &#123; stdio: 'pipe'&#125;);// child.stdin.pipe(子进程.stdin)child.stdin.write("hello child!");child.stdout.on("data", function(chunk) &#123; console.log("父进程的stdout接收到: " + chunk.toString());&#125;); 123456// child.js// process.stdout.pipe(ChildParent.stdout)// stderr同理process.stdin.on("data", function(chunk) &#123; process.stdout.write("子进程的stdin接收到: " + chunk.toString());&#125;); 这个示例调用了child.stdin.write向子进程的stdin写入了”hello child!”，而子进程监听了process.stdin的data事件，然后把数据写入process.stdout，process.stdout则将数据再交给父进程的child.stdout，通过child.stdout的data事件获取，到此完成了双向通讯，输出结果如下： 1父进程的stdout接收到: 子进程的stdin接收到: hello child! inherit - 共享IO如果将stdio设置为’inherit’，则可以让子进程共享父进程的标准IO，二者共用同一套stdio。相当于[process.stdin, process.stdout, process.stderr]或者[0, 1, 2]（因为标准IO套接字就是0、1、2）。 需要注意的是，如果分开设置标准IO，可以将其中一个输入输出指定成某个流或者套接字，比如一个socket stream。 ipc - 进程间通信当stdio是一个数组，并且拥有ipc值的时候将为开启IPC通道（仅能开一个），子进程将可以使用process.send向父进程发送消息，父进程可以通过监听ChildProcess的message事件来获取该消息。使用fork函数建立子进程时默认开启双向IPC通道，父进程也可以调用ChildProcess的send方法向子进程发送消息。 12345678910var child_process = require("child_process");var child = child_process.spawn("node", ['./child.js'], &#123; stdio: [ 'ipc']&#125;);child.on("message", function(message) &#123; console.log("master: " + message);&#125;);child.send("hello child!"); 123456// child.js process.send("hello master!");process.on("message", function(message) &#123; console.log("child:" + message);&#125;); 运行node test.js之后，将能够看到输出的内容是： 1master: hello master! 这个结果看起来并不符合我们的本意，因为主进程调用了child.send向子进程发送”hello child!”却没有输出来，但这是正常的，因为子进程压根就没有开启标准输入输出，test.js代码需要做一下小调整： 1234567891011var child_process = require("child_process");var child = child_process.spawn("node", ['./child.js'], &#123; // 与子进程共享本进程的标准IO，子进程也能够向控制台输出信息了 stdio: [0, 1, 2, 'ipc']&#125;);child.on("message", function(message) &#123; console.log("master: " + message);&#125;);child.send("hello child!"); ignore - 忽略IO当给子进程设置标准IO为ignore时，子进程将会把标准IO指向/dev/null，Unix会忽略对这个空设备的读写操作，相当于没有打开任何IO设备，可以单独为某个IO设置ignore值，比如[0, ‘ignore’, ‘ignore’]。 独立子进程detached默认为false，意味着子进程依附父进程运行，当父进程中断退出时子进程也会随之退出，父进程也会等待所有子进程退出运行才退出运行。如果将detached设置为true，那么父进程退出时子进程是不会退出运行的，它是一个独立的进程，父进程调用child.unref方法可以让子进程从父进程的事件循环中删除，父进程可以独立退出运行而不影响子进程。 123456789101112// test.jsvar child_process = require("child_process");// var fs = require("fs");// var outFile = fs.openSync("./out.log", "a");var child = child_process.spawn("node", ['./child.js'], &#123; // stdio: ['ignore', outFile, 'ignore'], detached: true, stdio: 'inherit'&#125;);child.unref();console.log("master exit!"); 123setTimeout(function() &#123; console.log("child exit!");&#125;, 1000); 有文章说stdio必须设置为ignore或者另开一个套接字，不能使用父进程的stdio，否则会导致高用child.unref方法时父进程还会等待子进程退出才退出，但我实际测试了并没有这种情况，或许是版本问题，我使用的是v7.0.0，如果发生这种情况可以按示例中注释掉的代码将子进程的stdout重定向到一个文件中。 子进程事件事件是子进程主动对外（父进程）发送消息的重要手段，ChildProcess对象提供了5种事件给父进程绑定： close - 当子进程退出时，如果stdio同时也关闭将会触发该事件。要特别注意的是，如果stdio没有关闭，则不会触发该事件，比如子进程与父进程共享stdio。 exit - 当子进程退出时触发该事件，并且告诉父进程退出信号代码。 disconnect - 当子进程与父进程之间的IPC通道关闭时触发。 error - 当子进程无法创建、无法kill以及无法发送消息的时候分发该事件。需要特别注意的是当发生错误退出时未必会分发exit事件，也可能会分发exit事件。 message - 当子进程调用process.send向父进程发送消息时分发 进程信号进程在支持POSIX的系统中实现了系统信号，具体列表请查阅POSIX信号列表。process可以监听部份允许监听的系统信号做出相应的处理，但也有很多信号是无法监听直接执行默认行为的。 以下是Node.js手册提供的部份信号解释： SIGUSR1 node.js 接收这个信号开启调试模式。可以安装一个监听器，但开始时不会中断调试。 SIGTERM 和 SIGINT 在非 Windows 系统里，有默认的处理函数，退出（伴随退出代码 128 + 信号码）前，重置退出模式。如果这些信号有监视器，默认的行为将会被移除。 SIGPIPE 默认情况下忽略，可以加监听器。 SIGHUP 当 Windowns 控制台关闭的时候生成，其他平台的类似条件，参见signal(7)。可以添加监听者，Windows 平台上 10 秒后会无条件退出。在非 Windows 平台上，SIGHUP 的默认操作是终止 node，但是一旦添加了监听器，默认动作将会被移除。 SIGHUP is to terminate node, but once a listener has been installed its SIGTERM Windows 不支持, 可以被监听。 SIGINT 所有的终端都支持，通常由CTRL+C 生成（可能需要配置）。当终端原始模式启用后不会再生成。 SIGBREAK Windows 里，按下 CTRL+BREAK 会发送。非 Windows 平台，可以被监听，但是不能发送或生成。 SIGWINCH - 当控制台被重设大小时发送。Windows 系统里，仅会在控制台上输入内容时，光标移动，或者可读的 tty在原始模式上使用。 SIGKILL 不能有监视器，在所有平台上无条件关闭 node。 SIGSTOP 不能有监视器。 可以利用kill方法向一个进程发送信号： 12345678var child_process = require("child_process");var child = child_process.spawn("node", ['./child.js'], &#123; stdio: 'inherit'&#125;);setTimeout(function() &#123; child.kill("SIGTERM");&#125;, 1000); 123456789process.on("SIGTERM", function() &#123; console.log("父进程发送SIGTERM信号要求子进程退出，但我不退出！");&#125;);process.on("exit", function() &#123; console.log("子进程退出了");&#125;);setTimeout(function() &#123;&#125;, 3000); 可以看出，kill方法并不是真的把子进程杀死，而是起到一个发送信号的作用，具体怎么处理完全取决于子进程。但并不是所有信号都会有给子进程反应的机会，如果将上边示例的kill调用参数换成”SIGKILL”，那么子进程完全没有输出任何信息的机会直接退出运行。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[浏览器事件循环以及多线程]]></title>
      <url>%2Farchivers%2F2016%2F11%2Fevent-loop-and-multi-thread%2F</url>
      <content type="text"><![CDATA[Javascript在浏览器中一直都是以单线程的方式运行，这意味着它同一时间只能干一件事，前端们不用担心你在读完一个变量的时候该变量马上被另一个线程修改而导致后续计算变得不准确，也不用担心对一个DOM节点做修改操作的时候突然它被删除。支持多线程的语言都有一个东西叫线程锁，但是Javascript作为操作HTML页面的脚本语言它应该足够简单，所以单线程是最合适的，但同样有方法实现多线程以提高系统资源利用率。 事件循环首先了解一下什么叫进程。进程就是一个应用程序在内存中的实例，一个CPU核心只能在同一时间处理一个进程的工作，操作系统同时在跑的应用程序当然不可能只有一个，所以操作系统就不停地把CPU资源交给其中一个进程，而其它没排到队的进程则进入沉睡状态。许多时候为了更好的利用起多核CPU的优势，一个进程往往会把自己fork成多个进程，让应用程序的工作能够同时在多个CPU上跑起来以达到利用更多CPU资源提高性能的目的，比如Node.js就是这么干的。 线程是轻量版的进程，一个进程可以拥有多个线程，线程也是CPU资源调度的最小单位，但线程与线程可以共享进程的公用资源。在超线程技术发明之后，多核多线程CPU再配上相应的操作系统、软件可以实现多个线程利用多个CPU核心的资源。 上边仅是简单地讲一下进程和线程，我对这方面并不擅长，或许有什么理解上的错误，但是GUI界面的应用程序一般都是对UI的交互交给一个线程处理，其它线程用于做计算。这样，其它线程在计算的同时不会阻塞了UI线程的运行，界面也就不会卡顿。 可能有人会提起setTimeout，说当我设置两个定时器，都是在1秒后执行，那么它们不就同时执行了吗？看起来像是多线程了，事实上二者不可能同时执行。使用setTimeout注册过的函数并不保证非常准时地执行，可能会延后一点时间执行，两个注册在定时器里的函数也是先后执行的，只有一个执行完了才会执行另一个。 这个先后关系是通过一个叫事件循环的东西来做调度的，页面上所有任务都会被放到一个先进先出的队列中进行排队，事件循环机制会从队列头取出一个任务执行，该任务完成后再取下一个任务执行。如果一个任务有大量的运算或费时的同步操作（比如同步ajax）将会导致下一个任务一直处于等待状态。 我们可以做一个实验： 12345678910111213141516171819202122232425262728293031&lt;!DOCTYPE html &gt;&lt;html&gt;&lt;head&gt; &lt;meta http-equiv="Content-Type" content="text/html; charset=utf-8" /&gt; &lt;meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" /&gt; &lt;meta name="renderer" content="webkit" /&gt; &lt;title&gt;测试&lt;/title&gt; &lt;script src="http://lib.sinaapp.com/js/jquery/1.7.2/jquery.min.js" type="text/javascript"&gt;&lt;/script&gt;&lt;/head&gt;&lt;body&gt; &lt;script type="text/javascript"&gt; console.time("begin"); setTimeout(function() &#123; console.timeEnd("begin"); &#125;, 1000); for (var i = 0; i &lt; 1000; i++) &#123; $.ajax(&#123; url: "./test.html", async: false, method: "get" &#125;); &#125; &lt;/script&gt;&lt;/body&gt;&lt;/html&gt; 在这个示例中，一开始就注册了个函数在一秒后输出从开始注册到开始执行的时间差，随后再调用ajax同步请求当前页面（./text.html）一千次，在我的机子上输出了”begin: 1.74e+03ms”，也就是事实上1740ms后才执行了setTimeout的回调函数。这是因为同步操作导致事件循环长时间耗在请求代码的任务上而没有开始下一个注册的任务。 事件循环的任务队列可以理解成是一个数组，每个数组元素都是一个函数（待执行的任务），它是一个同步执行的任务队列，事件循环机制会按顺序将它们一个一个执行，这个就是主线程任务队列。除了主线程任务队列之外还有一个异步的任务队列，这个异步任务队列里的任务并不会被主动执行，它会在它应该被执行的时候往主线程任务队列插入任务，setTimeout就是这种异步任务，网页上的各类事件也是类似的异步任务，它们随时向主线程任务队列插入任务。 初识Worker尽管在浏览器中脚本确实是以单线程的方式运行的，但考虑到可能会有大量数据计算之类的耗时操作，IE10以上版本以及其它标准浏览器都已经支持了Web Worker，它实现了Javascript在浏览器中多线程的需求，在一个Worker中不管做什么同步操作都不会影响到页面的操作，也不会导致页面卡顿（当然，你的硬件很差这个就回天无力了，毕竟系统资源就那么多）。 先来看一个简单的例子： 123456789101112131415console.time("timeout");setTimeout(function() &#123; console.timeEnd("timeout");&#125;, 100);console.time("concat");var str = "";for (var i = 0; i &lt; 10000000; i++) &#123; str = str + "abc";&#125;console.timeEnd("concat"); 在我机子上执行结果是： 12concat: 609mstimeout: 674ms 由于现在我们将字符拼接的代码放入Worker中执行： 123456789console.time("worker");var str = "";for (var i = 0; i &lt; 10000000; i++) &#123; str = str + "abc";&#125;console.timeEnd("worker"); 12345678var worker = new Worker("./worker.js");console.time("timeout");setTimeout(function() &#123; console.timeEnd("timeout");&#125;, 100);console.time("worker"); 很惊人地结果： 12timeout: 100msworker: 109ms 虽然并不是每次都一样，但基本上timeout都是100ms，而worker都是100ms出头，也就是说从性能上看提高幅度非常大。为什么同样的代码在页面上执行需要609ms，而在worker中却只需要109ms？按我的理解是浏览器主页面线程的脚本是跟整个页面的各种任务在抢资源，而worker则是另起一线程独占了一份独立的CPU资源，自然运行速度就快很多了。 在MDN上关于Worker的介绍有一段文字很自信地拍着胸口向使用者们保证Worker的线程安全问题： Worker 接口会生成真正的操作系统级别的线程，如果你不太小心，那么并发(concurrency)会对你的代码产生有趣的影响。然而，对于 web worker 来说，与其他线程的通信点会被很小心的控制，这意味着你很难引起并发问题。你没有办法去访问非线程安全的组件或者是 DOM，此外你还需要通过序列化对象来与线程交互特定的数据。所以你要是不费点劲儿，还真搞不出错误来。 MDN使用 Web Workers Worker在运行期间与主线程几乎是完全分开的，二者无法直接共享数据，Worker也不能直接操作页面的DOM节点，简单来说不能把它当面浏览器中的普通脚本，它的环境更加纯净。 Worker可以做以下几件事： 与主线程互相通讯 使用XMLHttpRequest发起请求 使用定时器 除此之外，Worker同时能够使用许多函数以及小量的限制版对象，比如location以及navigator。这方面的信息可以查阅《Worker支持的函数》。 使用Worker初始化Worker初始化非常简单，直接使用new关键词新建一个实例，传入新线程代码所在的脚本文件路径(注意：必须遵守同源策略，但Worker内部使用importScripts函数加载的代码则不需要遵守，你可以加载CDN上的jquery库)，比如： 1var worker = new Worker("./test.js"); 事实上为了减少http请求，除了IE之外的浏览器还支持用URL对象当参数： 12345678910111213141516171819202122232425&lt;script type="text/code" id="worker-code"&gt; console.time("inline worker"); var str = ""; for (var i = 0; i &lt; 1000000; i++) &#123; str = str + "abc"; &#125; console.timeEnd("inline worker");&lt;/script&gt;&lt;script type="text/javascript"&gt; var code = document.getElementById("worker-code").innerHTML; var blob = new Blob(Array.from(code), &#123; type: "text/javascript" &#125;); var url = URL.createObjectURL(blob); var worker = new Worker(url); console.time("timeout"); setTimeout(function() &#123; console.timeEnd("timeout"); &#125;, 100); console.time("worker");&lt;/script&gt; 在我的机子上，运行结果是： 12timeout: 101ms inline worker: 108ms 其实跟前边的运行结果没什么区别，本来timeout就有可能延时执行。我个人是比较推荐内嵌worker代码在页面或者放入javascript代码内执行（很简单啊，写个函数然后toString一下就得到它的代码了…），这样可以节省http请求，加载Worker的脚本文件也是要花时间的，尽管浏览器很聪明地帮我们隐藏了一切，你可以把它当成瞬间就加载完一般使用，这个后边会讲。 线程通讯Worker线程可以与主线程通讯，这主要是通过postMessage以及message事件来实现，并且可以传递序列化后的数据给对方： 123456789101112131415161718192021&lt;script type="text/code" id="worker-code"&gt; addEventListener("message", function(ev) &#123; // ev是一个message对象，可以用这种方法看它的结构 // console.dir(ev); console.log("worker accept: %s", ev.data); postMessage("hello master"); &#125;);&lt;/script&gt;&lt;script type="text/javascript"&gt; var code = document.getElementById("worker-code").innerHTML; var blob = new Blob(Array.from(code), &#123; type: "text/javascript" &#125;); var url = URL.createObjectURL(blob); var worker = new Worker(url); worker.addEventListener("message", function(ev) &#123; console.log("master accept: %s", ev.data); &#125;); worker.postMessage("hello worker");&lt;/script&gt; 在主线程中首先创建了一个Worker，并为该Worker绑定了message事件用于响应来自Worker post过来的消息。Worker同样使用绑定了message事件，用于接收来自主线程的消息并随后向主线程发送消息，这就是最简单的通讯方式。这段代码在我的机子上运行结果如下： 12worker accept: hello workermaster accept: hello master 一般来说线程之间无法互相post对象，只能post可序列化的数据，比如将示例中的代码稍改一下： 123456789101112131415161718192021&lt;script type="text/code" id="worker-code"&gt; addEventListener("message", function(ev) &#123; // ev是一个message对象，可以用这种方法看它的结构 // console.dir(ev); console.log("worker accept: %s, type: %s"); postMessage("hello master"); &#125;);&lt;/script&gt;&lt;script type="text/javascript"&gt; var code = document.getElementById("worker-code").innerHTML; var blob = new Blob(Array.from(code), &#123; type: "text/javascript" &#125;); var url = URL.createObjectURL(blob); var worker = new Worker(url); worker.addEventListener("message", function(ev) &#123; console.log("master accept: %s", ev.data); &#125;); worker.postMessage(document);&lt;/script&gt; 该示例将document对象post过去，然后报了这样的异常：Uncaught DOMException: Failed to execute ‘postMessage’ on ‘Worker’: An object could not be cloned.意思是说document无法被复制一个副本用于post。 没错，postMessage方法在传递数据的时候是复制一个副本而不是直接将内容本身送过去，类似于函数传递参数，函数的参数就相当于函数的局部变量，它是外部传递进来的值的一个副本，二者毫无关系互不影响。而document对象却无法复制（只要是DOM对象皆如此），无法传递对象的引用。 或许现在你会马上尝试传递一个普通的Javascript对象过去，可以的，一点问题都没有！因为普通的对象依然是可以通过JSON.stringify(obj)的方式转换成json字符串。我尝试过，确实非常方便，在Worker内部接收到的自动帮我们反序列化成一个跟原来一模一样的对象。要注意的是：该对象依然是原来对象的一个副本，在Worker中进行修改并不会导致主线程的对象发生改变！ 12345678910111213141516171819202122232425&lt;script type="text/code" id="worker-code"&gt; addEventListener("message", function(ev) &#123; var obj = ev.data; console.log("worker: %s", JSON.stringify(obj)); ev.data.value = "world"; // &#123; "value": "world" &#125; 值已经改变 console.log("worker: %s", JSON.stringify(obj)); postMessage("ok!") &#125;);&lt;/script&gt;&lt;script type="text/javascript"&gt; var code = document.getElementById("worker-code").innerHTML; var blob = new Blob(Array.from(code), &#123; type: "text/javascript" &#125;); var url = URL.createObjectURL(blob); var worker = new Worker(url); var obj = &#123; value: "hello" &#125;; worker.addEventListener("message", function(ev) &#123; // 检查一下外部的obj console.log("master: %s", JSON.stringify(obj)); &#125;); worker.postMessage(obj);&lt;/script&gt; 这就是输出结果，符合我上边的说法： 123worker: &#123;&quot;value&quot;:&quot;hello&quot;&#125; worker: &#123;&quot;value&quot;:&quot;world&quot;&#125; master: &#123;&quot;value&quot;:&quot;hello&quot;&#125; 但这种做法并不能让我们比较满意，如果需要传输一段文件内容，那么这个序列化、复制、反序列化的过程将会比较耗时。还好，Worker提供了一种方式可以让我们某些类型的对象直接传递引用过去，但出于线程安全考虑，该对象在原来的上下文中会消失！也就是如果主线程将对象转让给Worker之后，主线程就访问不到该对象了。根据文档中描述，现阶段仅有MessagePort以及ArrayBuffer两种对象可以用于转让。 postMessage方法其实拥有两个参数，第二个参数是一个可选的数组，用于放置转让对象列表： 1234567891011121314151617181920212223&lt;script type="text/code" id="worker-code"&gt; addEventListener("message", function(ev) &#123; var typeArray = ev.data; // 1, 2, 3 console.log(typeArray.toString()); postMessage("ok"); &#125;);&lt;/script&gt;&lt;script type="text/javascript"&gt; var code = document.getElementById("worker-code").innerHTML; var blob = new Blob(Array.from(code), &#123; type: "text/javascript" &#125;); var url = URL.createObjectURL(blob); var worker = new Worker(url); var typeArray = new Int8Array([1, 2, 3]); worker.addEventListener("message", function(ev) &#123; // Int8Array[0] console.dir(typeArray); &#125;); worker.postMessage(typeArray, [typeArray.buffer]);&lt;/script&gt; 示例将typeArray传递给Worker，它将被序列化。但在postMessage时却将typeArray的buffer列在转让列表中，要求该对象直接进行转让，也就是说在Worker中复制的typeArray使用的ArrayBuffer对象其实就是主线程中的typeArray使用的ArrayBuffer，它并没有经过复制。在Worker得到typeArray之后，重新发了个消息通知主线程，这时候主线程再来做检查，外部的typeArray还在（因为仅是复制了一份），但它的buffer却不见了，缓冲区变成0字节。 这里必须强调一点，转让列表中的对象必须是postMessage第一个参数的本身或者一部份，如果与它毫无关联那么在Worker内部无法得到它。 停止Worker想要将一个Worker停止非常简单，worker对象提供了terminate方法，而Worker内部则可以调用close方法关闭本线程。 执行顺序Worker允许加载一个同源的js文件作为它的执行代码，同时在Worker内部可以使用importScripts函数无限制地跨域加载js文件。由于加载js文件是需要时间的，在执行过程中它们是同步的还是异步的还需要进行实验： 123456789&lt;?phpsleep(1);header('Content-Type: application/javascript');?&gt;console.log("worker load: %d", new Date().getTime());addEventListener("message", function(ev) &#123; console.log("worker accept: %s, time is %d", ev.data, new Date().getTime());&#125;); 1234console.log("worker create: %d", new Date().getTime());var worker = new Worker("./worker.php?t=" + new Date().getTime());worker.postMessage("here?")console.log("master send: %d", new Date().getTime()); worker.php文件先来了个sleep(1)睡眠了1秒才开始返回数据，也就是说Worker是至少1秒后才开始工作。而主线程在建立Worker之后马上发送一句”here?”并输出时间，现在看一下运行结果，令人惊讶： 1234worker create: 1480097663629master send: 1480097663631worker load: 1480097664656worker accept: here?, time is 1480097664660 “worker create”与”master send”之间的时间间隔是2ms，也就是说几乎同时执行，证明建立一个Worker并不是同步操作。在1000ms后控制台出现”worker load”，证明Worker真的是1秒后才开始工作，但后边的”worker accept”却表示它接收到了”here?”。按常理来说消息是在Worker运行前一秒发的，当Worker开始运行时消息早已经丢失，因为在发送时没人接收，但事实上并非如此。 现在再将php代码稍改改看看运行结果： 1234567891011&lt;?phpsleep(1);header('Content-Type: application/javascript');?&gt;console.log("worker load: %d", new Date().getTime());setTimeout(function() &#123; addEventListener("message", function(ev) &#123; console.log("worker accept: %s, time is %d", ev.data, new Date().getTime()); &#125;);&#125;, 100); 我将message事件的绑定放到setTimeout之中，也就是0.1秒后才绑事件，运行结果如下： 123worker create: 1480098216641master send: 1480098216643worker load: 1480098217667 这次Worker真的接收不到未执行前发送的消息了。由此可见Worker的执行代码加载确实是异步的，在Worker加载期间主线程发送的消息都会被暂存起来，直到Worker开始执行并且绑定了message事件，浏览器才会将保存起来的消息真的发送过去，但是在Worker脚本执行完之后还没碰上事件绑定，消息就真的被抛弃了，哪怕你在某个时刻终于想起要绑定message事件都无法收到消息。浏览器在这方面封装得非常棒，至少我们不需要确保Worker绑定事件后才开始发送消息，唯一需要注意的是必须在Worker的全局作用域下直接绑个message事件而不能在某个异步操作之后再绑。 需要考虑执行顺序的还有Worker内部的importScripts数，它能够加载一个js文件在当前作用域下执行，但这个我们无需试验，因为MDN上说得非常清楚： 注意： 脚本的下载顺序不固定，但执行时会按照你将文件名传入到 importScripts() 中的顺序。这是同步完成的；直到所有脚本都下载并运行完毕， importScripts() 才会返回。 MDN使用 Web Workers 也就是说importScripts是一个同步操作，它允许你一次传入多个文件路径导入并执行，虽然这些文件由于网络原因加载完成的时间不一样，但Worker会保证它们在全部加载完之后再执行，而且执行顺序跟参数的顺序一致。 12importScripts("a.js", "b.js", "c.js");// other code]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[数据存储方式 - endian]]></title>
      <url>%2Farchivers%2F2016%2F11%2Fendian%2F</url>
      <content type="text"><![CDATA[现有两大CPU派系PowerPC以及Intel在数据存储上存在着差异，二者分别采用了big-endian以及little-endian方式保存一个多字节的数字。原本我从来没关注过这个问题，现有的工具已经把它们的差异封装得很好了，直到我最近尝试去操作了一些二进制数据才意识到我需要关注一下。数据在内存中是以二进制方式存储的，一个字节可以存储一个8位的整型，有符号整型可以存储-128至127，而无符号整型可以存储0-255。无符号整型255写成二进制以及十六进制形式是： 1111 1111F F 也就是范围用16进制表示是0x00至0xff，我们后边就用两个16进制的字符来表示一个字节的值。 网上有篇文章讲解endian，使用了0x12345678作为例子，我觉得非常好，事实上我也是参考了那篇文章，并把自己的理解写在这。这个数字是8个16进制字符，按2个字符1个字节算其实它就是一个32位的无符号整型，即4个字节，按照我们的书写习惯它应该是这么写的： 这种写法被称为big-endian，它的存储原则是高位优先，从高位字节到低位字节按顺序写到相邻的四个字节中，PowerPC采用的正是这种方式。 Intel采用是little-endian，它的存储原则是低位优先，从低位字节到高拉字节按顺序写到相邻的四个字节中，也就是big-endian反过来： 二者到底有什么优缺点呢？ big-endian相对来说更符合人类阅读习惯 big-endian在判断数字的正负上比较有优势，只要取第一个字节的一个位的值就可以判断。 little-endian在数据类型转换上比较有优势，因为同一个数字在不同位数的数据类型中排列完全相同。 关于类型转换我们试着用一个无符号整型10（二进制为1010）在8位、16位、32位整型中的存储方式说明: big-endian &nbsp;&nbsp;8位 0000 101016位 0000 0000 0000 101032位 0000 0000 0000 0000 0000 0000 0000 1010 little-endian &nbsp;&nbsp;8位 0000 010116位 0000 1010 0000 000032位 0000 1010 0000 0000 0000 0000 0000 0000 从示例中可以看出，如果使用little-endian保存数据，32位的10转成16位的10需要从左到右复制16位，转成8位则是复制8位，后边直接截断不管了，极其方便。而big-endian方式则需要移动位游标再进行复制，性能上是little-endian更高。 需要提一下的是，网络上传输数据时一率采用big-endian进行传输，这是为了防止数据源跟数据接收端使用的存储方式不同而导致发生数据错乱。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Node.js - buffer模块]]></title>
      <url>%2Farchivers%2F2016%2F11%2Fnode-buffer%2F</url>
      <content type="text"><![CDATA[刚把Javascript本身新引入的TypeArray以及ArrayBuffer好了解了一下，Node.js针对二进制数据提供了buffer模块，手册中提到Buffer是Int8Array的另一种更适合Node.js使用的实现方式（我看是因为之前TypeArray还没实现结果先出了Buffer，现在准备一条道走到黑吧……不过确实用起来挺好用）。在Node.js的数据交换过程中，buffer模块经常会被使用到，比如数据流。 Buffer的初始化使用buffer模块不需要使用require引入模块，全局提供了一个Buffer对象（可见它使用频率有多频繁）。虽然Buffer可以使用new关键词创建一个实例，但手册上明确表示它已经被弃用，我们应该使用alloc之类的API创建。 需要特别注意的是： Buffer是固定大小的（fixed-size），从实例化后就无法再改变它的内存大小。 Buffer是动态申请的内存，它并不在V8引擎的堆里。 Buffer.form(array)从数组中创建Buffer，需要注意的是这里的数组是指普通的Array、TypeArray以及类数组的的对象。需要注意的是从数组或类数组对象创建的Buffer是新申请内存并且把数组内容复制到Buffer中。 12345678910111213141516171819202122232425// 普通数组var buffer = Buffer.from([1, 2, 3]);// &lt;Buffer 01 02 03&gt;console.log(buffer);// TypeArraybuffer = Buffer.from(new Int8Array([2, 3, 4]));// &lt;Buffer 02 03 04&gt;console.log(buffer);// 试一下TypeArrayvar arrayBuffer = new ArrayBuffer(10);var int8Array = new Int8Array(arrayBuffer);// 从TypeArray创建buffer = Buffer.from(int8Array);int8Array[0] = 12;// &lt;Buffer 00 00 00 00 00 00 00 00 00 00&gt;// 第一个字节没有变，证明这里是复制了一个副本console.log(buffer);// 如果想让它们共享内存，可以从TypeArray的缓冲区创建：buffer = Buffer.from(int8Array.buffer);// &lt;Buffer 0c 00 00 00 00 00 00 00 00 00&gt;console.log(buffer); Buffer.from(arrayBuffer[, byteOffset [, length]])从ArrayBuffer中创建Buffer，同时可以指定开始的位置byteOffset以及字节数length。需要注意的是从ArrayBuffer创建的Buffer是与ArrayBuffer共享内存的，随便改哪个都会导致另一个更新。 1234567891011var arrayBuffer = new ArrayBuffer(10);var int8Array = new Int8Array(arrayBuffer);var buffer = Buffer.from(arrayBuffer);// &lt;Buffer 00 00 00 00 00 00 00 00 00 00&gt; 初始值console.log(buffer);int8Array[0] = 10;// &lt;Buffer 0a 00 00 00 00 00 00 00 00 00&gt;// 第一个字节变成了10，证明从arrayBuffer创建的是共享内存的console.log(buffer); Buffer.alloc(size[, fill[, encoding]])直接申请一段内存，内存大小为size个字节。新申请的内存每个字节默认将值填为0，也可以通过fill设置填充选项。注意这里相当于调用了buffer的fill方法，填充编码默认为utf-8。 123456789// &lt;Buffer 61 61 61 61 61 61 61 61 61 61&gt;// 使用'a'填充每个字节var buffer = Buffer.alloc(10, 'a');console.log(buffer);// 使用'ab'填充整个buffer，由于buffer长度为10，ab会被不断循环填充。// 同时指明编码格式为utf-8buffer = Buffer.alloc(10, 'ab', "utf-8");console.log(buffer); Buffer.allocUnsafe(size)直接申请一段内存，内存大小为size个字节。与alloc不同的是，它标明了是”unsafe”，其实就是申请内存时不使用0将原有内存内容擦除因此不安全，但也因此它相对于alloc来说更快。 123var buffer = Buffer.allocUnsafe(10);// 每次buffer的内容都是不可预知的console.log(buffer); Buffer.allocUnsafeSlow(size)申请一段内存，内存大小为size个字节。这个函数使用了Slow这个词，它的意思是说这块内存将是独享的，不允许Buffer按照规则决定是否从预申请的内存池中分配内存（因此它是缓慢的，大概就是这个意思）。事实上，所有不符合内存池分配规则的Buffer都是独享的，只不过这里特地要求不考虑与其它Buffer共享一块内存池罢了，没有什么大的区别。注意，这个方法平时不需要考虑使用，它更多的是提供给Node.js源码开发者使用的，普通开发者应该使用Buffer。 数据的读写Buffer针对各种数据类型提供了多种API用于读写操作，如果数据类型不是int8还需要区分字节序是高位优先还是低位优先，以BE(BIG_ENDIAN)和LE(LITTLE_ENDIAN)结尾区分。 Buffer的读写操作跟Javascript的TypeArray提供的读写操作非常类似，唯一需要注意的是noAssert参数，请谨慎使用该参数。noAssert如果被设置为true，意味着在写数据的时候不会检测写入的数据是否会超出当前Buffer分配给数据存储的内存区域！这可能会导致灾难性地问题。 Buffer允许把它当数组一般使用下标读写某个字节，但同时也提供了大量的方法方便读写： 读操作 readInt8(offset[, noAssert]) - 读取一个8位的整型 readUInt8(offset[, noAssert]) - 读取一个8位的无符号整型 readInt16BE(offset[, noAssert]) - 高位优先读取16位整型 readInt16LE(offset[, noAssert]) - 低位优先读取16位整型 readUInt16BE(offset[, noAssert]) - 高位优先读取16位无符号整型 readUInt16LE(offset[, noAssert]) - 低位优先读取16位无符号整型 readInt32BE(offset[, noAssert]) - 高位优先读取32位整型 readInt32LE(offset[, noAssert]) - 低位优先读取32位整型 readUInt32BE(offset[, noAssert]) - 高位优先读取32位无符号整型 readUInt32LE(offset[, noAssert]) - 低位优先读取32位无符号整型 readFloatBE(offset[, noAssert]) - 高位优先读取32位浮点数 readFloatLE(offset[, noAssert]) - 低位优先读取32位浮点数 readDoubleBE(offset[, noAssert]) - 高位优先读取64位浮点数 readDoubleLE(offset[, noAssert]) - 低位优先读取64位浮点数 readIntBE(offset, byteLength[, noAssert]) - 高位优先读取一个指定字节数的整型，最大48位 readIntLE(offset, byteLength[, noAssert]) - 低位优先读取一个指定字节数的整型，最大48位 readUIntBE(offset, byteLength[, noAssert]) - 高位优先读取一个指定字节数的无符号整型，最大48位 readUIntLE(offset, byteLength[, noAssert]) - 低位优先读取一个指定字节数的无符号 整型，最大48位 写操作 writeInt8(value, offset[, noAssert]) - 写入一个8位整型 writeUInt8(value, offset[, noAssert]) - 写入一个8位无符号整型 writeInt16BE(value, offset[, noAssert]) - 高位优先写入一个16位整型 writeInt16LE(value, offset[, noAssert]) - 低位优先写入一个16位整型 writeUInt16BE(value, offset[, noAssert]) - 高位优先写入一个16位无符号整型 writeUInt16LE(value, offset[, noAssert]) - 低位优先写入一个16位无符号整型 writeInt32BE(value, offset[, noAssert]) - 高位优先写入一个32位整型 writeInt32LE(value, offset[, noAssert]) - 低位优先写入一个32位整型 writeUInt32BE(value, offset[, noAssert]) - 高位优先写入一个32位无符号整型 writeUInt32LE(value, offset[, noAssert]) - 低位优先写入一个32位无符号整型 writeFloatBE(value, offset[, noAssert]) - 高位优先写入一个32位浮点数 writeFloatLE(value, offset[, noAssert]) - 低位优先写入一个32位浮点数 writeDoubleBE(value, offset[, noAssert]) - 高位优先写入一个64位浮点数 writeDoubleLE(value, offset[, noAssert]) - 低位优先写入一个64位浮点数 write(string[, offset[, length]][, encoding]) - 将一个字符串写入指定的位置，可以通过length限制长度以及通过encoding设置编码，编码默认是UTF-8。 writeIntBE(value, offset, byteLength[, noAssert]) - 高位优先将value值写入指定的位置，需要明确指定value值占的位数 writeIntLE(value, offset, byteLength[, noAssert]) - 低位优先将value值写入指定的位置，需要明确指定value值占的位数 序列化Buffer提供了几种方法可以将内容序列化： toString([encoding[, start[, end]]])以指定的编码返回指定范围的字符串，默认是使用UTF-8，返回全部内容。 123var buffer = Buffer.from("hello world");// world 注意，d的下标是10，这里如果设置end，返回的字符串是不包含end下标的字符的。console.log(buffer.toString("utf-8", 6, 11)); toJSON()将Buffer以{“type”:”Buffer”,”data”:[1,2,3,4,5]}的方式返回一个JSON对象，个人感觉它的格式很死板。 1234var buffer = Buffer.from("hello world");// &#123; type: 'Buffer',// data: [ 104, 101, 108, 108, 111, 32, 119, 111, 114, 108, 100 ] &#125;console.log(buffer.toJSON()); 字节序处理涉及到多字节数据的读写的API都得考虑字节序的问题，在Buffer提供的API中，读写操作基本上都以BE以及LE后缀结尾。当你明确知道当前数据是以高位优先或者低位优先存储，却希望将其做转换的话可以使用以下三个API进行数据处理： swap16() - 将当前Buffer的数据每两个字节视为一个16数字，并反向重排字节。 swap32() - 将当前Buffer的数据每两个字节视为一个32数字，并反向重排字节。 swap64() - 将当前Buffer的数据每两个字节视为一个64数字，并反向重排字节。 以16位数字（int16/uint16)为例： 12345678910111213141516171819202122232425262728293031// 8个字节，可以存放4个int16var buffer = Buffer.allocUnsafe(8);buffer.writeInt16BE(0x0102, 0);buffer.writeInt16BE(0x0304, 2);buffer.writeInt16BE(0x0506, 4);buffer.writeInt16BE(0x0708, 6);// &lt;Buffer 01 02 03 04 05 06 07 08&gt;// 高位优先，符合人类阅读习惯console.log(buffer);// 我认为我现在需要低位优先方式存储，调用swap16进行整理buffer.swap16();// &lt;Buffer 02 01 04 03 06 05 08 07&gt;// 它以2个字节为单位将字节顺序调换console.log(buffer);// 重置一下buffer.writeInt16BE(0x0102, 0);buffer.writeInt16BE(0x0304, 2);buffer.writeInt16BE(0x0506, 4);buffer.writeInt16BE(0x0708, 6);// 看看swap32会有啥结果buffer.swap32();// &lt;Buffer 04 03 02 01 08 07 06 05&gt;// 它认为4个字节是一个整体，以4个字节为单位将字节顺序调换console.log(buffer); 缓冲池与性能Buffer对象有一个属性叫poolSize，用于设置缓冲池的大小。以下是这个缓冲池的关键性代码，来自Node.js(v6.9.1/lib/buffer.js)源码： 1234567891011121314151617181920212223242526272829303132Buffer.poolSize = 8 * 1024;// ....function createPool() &#123; poolSize = Buffer.poolSize; allocPool = createUnsafeBuffer(poolSize); poolOffset = 0;&#125;createPool();// ....function allocate(size) &#123; if (size &lt;= 0) &#123; return new FastBuffer(); &#125; if (size &lt; (Buffer.poolSize &gt;&gt;&gt; 1)) &#123; if (size &gt; (poolSize - poolOffset)) createPool(); var b = allocPool.slice(poolOffset, poolOffset + size); poolOffset += size; alignPool(); return b; &#125; else &#123; // Even though this is checked above, the conditional is a safety net and // sanity check to prevent any subsequent typed array allocation from not // being zero filled. return createUnsafeBuffer(size); &#125;&#125; createPool函数从内存中申请了8kb的内存，并将其作为当前Buffer的缓冲池。 allocate函数用于分配内存，以下是我对它的注解： 123456789101112131415161718192021222324function allocate(size) &#123; // 当外部申请的内存小于等于0，则直接返回一个FastBuffer // FastBuffer是使用Uint8Array实现的Buffer，这个不在我们关注的话题内 if (size &lt;= 0) &#123; return new FastBuffer(); &#125; // 当申请的内存大小小于缓冲池大小的一半时就开始尝试从已经存在的缓冲区中分配内存 if (size &lt; (Buffer.poolSize &gt;&gt;&gt; 1)) &#123; // 如果申请的内存比当前空闲的缓冲池内存（有一部份被用掉给别的Buffer了）还大时 // 直接放弃当前缓冲池重建一个新的！ if (size &gt; (poolSize - poolOffset)) createPool(); var b = allocPool.slice(poolOffset, poolOffset + size); poolOffset += size; alignPool(); return b; &#125; else &#123; // Even though this is checked above, the conditional is a safety net and // sanity check to prevent any subsequent typed array allocation from not // being zero filled. // 直接申请新的内存返回 return createUnsafeBuffer(size); &#125;&#125; 从上边的源码解析中可以看到几个点： 为了节省申请内存消耗，Buffer直接申请了一块8kb的内存空间当成缓冲池随时用于存放小量数据 如果新建Buffer缓冲区大小小于当前设置的poolSize的一半时（4kb），则会使用缓冲池里的空闲内存分配，省掉申请内存消耗 如果新建Buffer需要的缓冲区大小满足缓冲池分配内存的原则，但当前缓冲池的空余内存又不够用，当前缓冲池会被直接浪费掉，直接申请新的8kb缓冲池。 这其实就是用空间换时间的做法，Node.js没有在缓冲池的内存管理上花什么心思，就是不够了就浪费掉申请新的，但很多时候数据量都不会超过4kb，也就是我们大部份操作都不会导致Buffer动态申请内存，提高了性能。 这里特别要注意的是，由于8kb的缓冲池是一次性申请的，只有缓冲池上所有Buffer都设置为null，否则整块缓冲池都不会被释放，也就是内存泄露。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[缓冲数组以及数据视图]]></title>
      <url>%2Farchivers%2F2016%2F11%2Farraybuffer-and-dataview%2F</url>
      <content type="text"><![CDATA[Javascript在数据的处理上一直不是强项，比如数字不分整型和浮点数统一使用了64位浮点数，如果涉及到二进制运算则显得非常无力，在数据传输上也非常浪费带宽。在ES6针对Javascript二进制数据处理上的无力引入了原始缓冲区ArrayBuffer，并且还提供了多种位数的int类型数组以及数据视图来处理数据。 ArrayBufferArrayBuffer是ES6新引入的用于处理二进制数组的缓冲区对象，它不提供对数据的操作能力，提供的是二进制数据的存储。 ArrayBuffer跟Array比较相似，它是一个定长的数组，在初始化后就无法改变长度。每个元素都是一个字节（8bit），相当于C语言中的char，所以如果它的长度是10，就是10字节，绝无例外。 在这里要特别提一下，我们平时编程所需的所有的数据都可以用不同数量的byte表示，比如32位系统中的int类型长度是4，其实它就是拿4个连续的字节拼凑而成的一段空间。 ArrayBuffer就是以字节为单位的缓冲区，再配上对应的API（TypeArray or DataView）来做数据的操作。 ArrayBuffer需要使用new关键词进行实例化，参数为缓冲区的大小： 1var buffer = ArrayBuffer(1024); // 1024个字节，即1kb 它提供了一个属性以及一个方法： byteLength - 只读属性，获取本缓冲数组的长度，由于一个元素就是1字节，其实这里也可以当成该缓冲区申请了多少字节的内存空间。 slice(begin[, end]) - 返回一个新的ArrayBuffer，并使用当前ArrayBuffer从begin到end之间的数据填充，如果end省略则是从begin到缓冲区结束。 同时它还提供了一个静态方法： ArrayBuffer.isView(arg) - 如果参数是TypeArray或者DataView，则返回true，否则返回false。 数据视图之前提到过ArrayBuffer仅仅是提供了对数据的存储，相当于动态申请了一段内存（当然你不需要像C/C++一般去释放它，或者在不需要的时候也可以将其设置为null由gc自动释放），对于这段缓冲区的操作则是由一组TypeArray以及灵活度更高的DataView对象来提供。 TypeArray类型数组提供了几种强类型数组对ArrayBuffer中的数据进行读写，其中包括： Int8Array - 8位的整型数组，由于ArrayBuffer每个元素就是1字节，也就是8位，所以Int8Array的长度就是ArrayBuffer的长度。 Uint8Array - 8位的无符号整型数组，int8使用了7位来保存数据，1位来当符号位以标识数据的正负，而无符号整型则将8位全部用来保存数据，只能保存非负整数，同样它的长度是ArrayBuffer的长度。 Uint8ClampedArray - 8位的无符号整型数组，它与Uint8Array在处理超出范围的数据上的做法略有不同。 Int16Array - 16位的整型数组，使用2个字节凑成一个int16，也就是ArrayBuffer(1024)可以被当成一个长度为512的int16数组使用。 Uint16Array - 16位的无符号整型数组，与Uint8Array类似，仅是每个元素由两个字节组成。 Int32Array - 32位的整型数组，使用4个字节凑成一个int32，也就是ArrayBuffer(1024)可以被当成一个长度为256的int32数组使用。 Uint32Array - 32位的无符号整型数组 Float32Array - 32位的IEEE浮点数数组（单精度float） Float64Array - 64位的IEEE浮点数数组（双精度float) 吐槽一下：这些类型数组以及ES6新引入的类、TypeScript什么的都感觉像是在打以前吹揍着”脚本语言就应该简单，弱类型是多么的方便”的大神们的脸。 曾几何时，我还在流着冷汗看着试卷想着int在32位系统上应该是占了几位，long又是占了几位，没想到当了前端还是要面对它们，感谢ECMA。 类型数组提供的初始化方式、API都是一模一样的，除了元素类型。 初始化初始化一个TypeArray有多种方法： new TypeArray(length)指明元素个数来创建一个类型数组： 12345678910// 直接创建一个1024个元素的var length = 1024;// 占了1024 * 1个字节，即1024个字节var int8Array = new Int8Array(length);console.log(int8Array.byteLength); // 1024// 占了1024 * 2个字节，即2048个字节var int16Array = new Int16Array(length);console.log(int16Array.byteLength); // 2048 new TypeArray(typedArray)从一个已经存在的类型数组创建新的类型数组，要特别注意的是它们仅仅是复制关系。 12345678var int8Array = new Int8Array(1024);console.log(int8Array.byteLength); // 1024var int16Array = new Int16Array(int8Array);console.log(int16Array.byteLength); // 2048var newInt8Array = new Int8Array(int16Array);console.log(newInt8Array.byteLength); // 1024 这里需要考虑到一个情况，一个范围较大的类型可以安全地存放范围较小的类型值，可是反过来的话就不行了，比如int8的范围是-128到127，int16是-32768到+32767。下边示例则证明了如果发生了数据溢出，则会将数据的一部份截断，比如int16是2个字节，而int8是1个字节，那么将会保留一个字节，然后抛弃另一个字节，导致数据变化。 1234567891011var int16Array = new Int16Array(2);// 超出int8的数值范围了，int8的数字范围是-128到127int16Array[0] = 1290;int16Array[1] = 1024;var int8Array = new Int8Array(int16Array);// 在我的机子的运行结果是 "1290 1024 10 0"// 这里为什么会得到10和0，后边会解释console.log(int16Array[0], int16Array[1], int8Array[0], int8Array[1]); new TypeArray(object)从一个对象中创建类型数组，对象类型我只试出Array可以，应该还有其它的。 123var int16Array = new Int16Array([1, 2]);// Int16Array [ 1, 2 ]console.log(int16Array); new TypeArray(buffer [, byteOffset [, length]])从一个已经存在的ArrayBuffer对象中创建类型数组，同时可以指定开始的位置以及长度来针对ArrayBuffer的某个区域进行操作。 要特别注意的是，byteOffset是指从第几个字节算起，而length参数是指TypeArray拥有多少个元素。 12345678var buffer = new ArrayBuffer(1024);var int8Array = new Int8Array(buffer, 2, 2);var int16Array = new Int16Array(buffer, 2, 2);// 2 2console.log(int8Array.length, int8Array.byteLength);// 2 4 由于是int16，所以2个int16占了4个字节console.log(int16Array.length, int16Array.byteLength); 静态成员 TypeArray.BYTES_PER_ELEMENT - 返回该种TypeArray（注意，不要直接写TypeArray，应该是Int8Array之类的对象）每个元素占的字节数。 TypeArray.from(source[, mapFn[, thisArg]]) - 从一个可遍历的对象(Set、Array、String之类)中创建一个类型数组。这里要特别注意当你需要传第三个参数用来给mapFn当this的时候，请不要把mapFn写成箭头函数。 1234567891011121314151617181920212223242526272829303132var array = [1, 2, 3];var obj = &#123; a : 2 &#125;;// Int8Array [ 1, 2, 3 ]console.log(Int8Array.from(array));// Int8Array [ 2, 4, 6 ]console.log(Int8Array.from(array, (x) =&gt; (x + x)));// &#123;&#125;// &#123;&#125;// &#123;&#125;// Int8Array [ 2, 4, 6 ]// 请不要使用箭头函数！因为箭头函数的this是不可改变的！console.log( Int8Array.from(array, x =&gt; &#123; console.log(this); return x * 2; &#125;, obj));// &#123; a: 2 &#125;// &#123; a: 2 &#125;// &#123; a: 2 &#125;// Int8Array [ 3, 4, 5 ]// 不使用箭头函数后，obj生效了！console.log( Int8Array.from(array, function(x) &#123; console.log(this); return x + this.a; &#125;, obj)); TypeArray.of(element0[, element1[, …[, elementN]]]) - 将所有参数拼装成一个类型数组。要特别注意的是如果元素不合法，则会得到0. 1234// Int8Array [ 1, 2, 3, 0 ]console.log( Int8Array.of(1, 2, 3, [4, 5])); 成员变量 buffer - TypeArray内部使用的ArrayBuffer对象，如果将一个外部ArrayBuffer当参数构造了一个TypeArray，那么该buffer就是那个外部ArrayBuffer。如果为同一个ArrayBuffer建立两个TypeArray，当使用了其中一个TypeArray的API对数据做修改，另一个也会生效，因为它们使用了同一个数据源。 12345678910var buffer = new ArrayBuffer(2);var int8Array = new Int8Array(buffer);var int16Array = new Int16Array(buffer);// Int16Array [ 0 ] Int8Array [ 0, 0 ]console.log(int16Array, int8Array);int16Array[0] = 123456;// Int16Array [ -7616 ] Int8Array [ 64, -30 ]// 二者都变了，因为ArrayBuffer变了console.log(int16Array, int8Array); byteLength - 获取TypeArray使用的ArrayBuffer的字节长度，与length不同的是它的值是以字节计算的，所以不会因为TypeArray的类型不同而发生变化。 123456var buffer = new ArrayBuffer(1024);var int8Array = new Int8Array(buffer);var int16Array = new Int16Array(buffer);// 1024 1024console.log(int8Array.byteLength, int16Array.byteLength); byteOffset - 保存了当前TypeArray操作的缓冲区域的起始位置，它是按字节算的 123456var buffer = new ArrayBuffer(1024);var int8Array = new Int8Array(buffer, 1);var int16Array = new Int16Array(buffer);// 1 0 console.log(int8Array.byteOffset, int16Array.byteOffset); length - 保存了当前TypeArray的元素个数，该属性跟Array一致，在这里特地列出来是为了跟byteLength做对比。 123456var buffer = new ArrayBuffer(10);var int8Array = new Int8Array(buffer);var int16Array = new Int16Array(buffer);// 10 5console.log(int8Array.length, int16Array.length); 成员方法TypeArray实现了大部份Array的方法，所以你可以调用类似map、every之类的方法处理数据。这方面的方法与属性就不在这里数说了，仅列出Array没有的。 set(array|typeArray [,offset])将一个数组或者类型数组复制到TypeArray指定的位置中，如果不指定位置则是从头覆盖。如果数据超出范围，则会将数据截断。 12345678910var buffer = new ArrayBuffer(10);var int8Array = new Int8Array(buffer);// 注意，它必须是一个Array或者TypeArray！int8Array.set([5], 2);// Int8Array [ 0, 0, 5, 0, 0, 0, 0, 0, 0, 0 ]console.log(int8Array);// Int8Array [ 64, 0, 5, 0, 0, 0, 0, 0, 0, 0 ] 被截断了int8Array.set([123456]);console.log(int8Array); subarray([begin [,end]])返回指定开始以及结束位置之前的元素组成的新同类型TypeArray。这里要注意以下两点： 返回的新TypeArray与当前TypeArray是共享缓冲区的，也就是修改了其中一个的值，也同样会影响另一个。 返回的新TypeArray不包含end下标元素 12345678910var int8Array = new Int8Array([1, 2, 3, 4, 5]);var subarray = int8Array.subarray(1, 3);// Int8Array [ 2, 3 ]// 对应着int8Array[1]以及int8Array[2]，不包含int8Array[3]console.log(subarray);int8Array[2] = 20;// Int8Array [ 2, 20 ] 注意，subarray[1]被更改了console.log(subarray); DataViewDataView提供了相对TypeArray更为灵活的方式用于操作数据，从TypeArray的各种示例上看，TypeArray其实就对应着C语言的数组（定长、元素同类型），而DataView则可以操作类似结构体的东西，它允许你随时切换不同的类型读写数据。 初始化new DataView(buffer [, byteOffset [, byteLength]]) DataView只可以使用ArrayBuffer作为操作对象，同时允许指定操作区域，这个跟TypeArray是一致的。 123456789var buffer = new ArrayBuffer(10);var view = new DataView(buffer);// DataView &#123;// byteLength: 10,// byteOffset: 0,// buffer: ArrayBuffer &#123; byteLength: 10 &#125;// &#125;console.log(view); 成员变量与TypeArray一模一样，DataView拥有buffer、byteOffset以及byteLength三个成员变量，它们的作用也是一样的，所以这里不再详说。 成员方法DataView的成员方法提供了一系列的get、set方法，用法基本上一致： get 在byteOffset指定的位置读取相应类型的值，littleEndian指定数据存储是高位优先还是低位优先 getInt8(byteOffset) getUint8(byteOffset) getInt16(byteOffset [, littleEndian]) getUint16(byteOffset [, littleEndian]) getInt32(byteOffset [, littleEndian]) getUint32(byteOffset [, littleEndian]) getFloat32(byteOffset [, littleEndian]) getFloat64(byteOffset [, littleEndian]) set 在byteOffset指定的位置写入相应类型的值，littleEndian指定数据存储是高位优先还是低位优先 setInt8(byteOffset, value) setUint8(byteOffset, value) setInt16(byteOffset, value [, littleEndian]) setUint16(byteOffset, value [, littleEndian]) setInt32(byteOffset, value [, littleEndian]) setUint32(byteOffset, value [, littleEndian]) setFloat32(byteOffset, value [, littleEndian]) setFloat64(byteOffset, value [, littleEndian]) 12345var buffer = new ArrayBuffer(2);var view = new DataView(buffer);view.setInt8(0, 10);// 10console.log(view.getInt8(0)); 关于Endian方面请看后边章节。 数据的存储方式说说这些类型数组元素的数据表示方式吧！当然，我不打算在这里全部讲完，特别是IEEE规定的单精度浮点数和双精度浮点数是怎么用二进制表示的估计能另起一篇文章。 一个整型数字写成2进制之后以书写习惯来说左边是高位，右边是低位。举个例子，int8的5使用二进制是这么表示的： 10000 0101 最左边的0是符号位，表示非负数，101则是5的二进制写法。 负数无法使用非负数的规则来表示，比如-1用非负数的规则表示是： 11000 0001 考虑到-1如果加上1值应该为0，那么该值加上1却会变成-2： 11000 0010 也就是在计算方式上出现问题了，所以二进制是采用了补码的方式来表示，补码可以完全不考虑符号位，它的规则如下： 非负数直接用正常的二进制数表示 负数是绝对值二进制取反加1 按这种规则，-1的绝对值二进制是： 10000 0001 取反后是： 11111 1110 再加1则是： 11111 1111 我们再尝试给它加上1，看看值是多少： 11 0000 0000 明显高位溢出了，于是将高位多余的1截掉变成： 10000 0000 它的值如我们所料是0，这就是补码。uint8由于没有正负之分，它的所有值都是非负数，所以就不需要考虑补码。 数据溢出截断首先需要了解一下int16用二进制是如何表示的，以3850为例子，它的二进制表示方式是这样子的： 100001111 00001010 int16占了两个字节，因此它被截成两断，我们把左边的字节称为高位字节，右边的字节称为低位字节。在内存中它是如何存放的呢？建立一个Int8Array来看一下： 1234567891011var buffer = new ArrayBuffer(2);var int16Array = new Int16Array(buffer);var int8Array = new Int8Array(buffer);int16Array[0] = 3850;// Int16Array [ 3850 ]console.log(int16Array);// Int8Array [ 10, 15 ]console.log(int8Array); 从运行结果看，3850被截断成两个int8值： 12int8Array[0] = 10 = 00001010int8Array[1] = 15 = 00001111 看起来很反人类是吧？高位字节不是放在左边下标为0的字节上，却放在右边下标为1的字节上，跟我们的书写习惯反过来了！ 事实上，数据在内存中存储并没有硬性规则高位字节必须放在左边（虽然它更符合人类阅读习惯），具体实现也是根据当前CPU的实现。大多数计算机是以高位优先的顺序存放数据（即高位在左，低位在右），但基于Intel CPU的计算机则是反过来以低位优先存放数据，我的本子就是Intel CPU的，因此我的运行结果就是Int8Array [ 10, 15 ]，或许换个电脑就会变成Int8Array [ 15, 10 ]。 那么当数据溢出截断又是怎么处理的？尝试着给一个int8字节赋值3850，看看最终得到的值是什么: 123var int8Array = new Int8Array([3850]);//Int8Array [ 10 ]console.log(int8Array); 很明显，它把15抛弃了，也就是保存了低位字节，抛弃高位。事实上，溢出处理在各种CPU上都是保留低位能保留的字节，把高位的截断，这个与数据存储是按高位优先还是低位优先没什么关系。 字节序处理请先看以下示例代码在我机子上跑的情况： 123456789101112var buffer = new ArrayBuffer(2);var view = new DataView(buffer);var int16Array = new Int16Array(buffer);view.setInt8(0, 10);// 10console.log(view.getInt8(0))// 2560 用二进制表示是：00001010 00000000，console.log(view.getInt16(0));int16Array[0] = 10;// 2560!console.log(view.getInt16(0)); 仔细看结果，很明显，view使用的是高位优先的读写方式，而TypeArray使用的是低位优先的读写方式。在内存中两个字节的数据在setInt8(0, 10)的时候会变成 100001010 00000000 按照我计算机的读写规则应该是低位优先，也就是实际上这里应该被解读成 100000000 00001010 也就是得到10，但实际上使用view却得到了2560，也就是高位优先。 DataView默认是使用big-endian方式，也就是高位优先进行读写。但在读写多字节数据的时候，可以通过传入值为true的little-endian参数来要求使用低位优先规则读写数据。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Node.js - url模块]]></title>
      <url>%2Farchivers%2F2016%2F11%2Fnode-url%2F</url>
      <content type="text"><![CDATA[URL是每一位网虫都使用过的东西，我记得第一次上网吧玩的时候，网吧老板帮我输了一个地址，在那时候很出名的聊天室网站”碧海银沙”，那时候我觉得上网就是上这个网站聊天，这是我第一次接触到URL。 URL的结构Node.js手册非常形象的使用了下方这张图片作为解读URL结构的示例，图中很清楚地为我们构造出一个完整的URL应该是长什么样的。 Node.js的url模块能够让工程师将一个URL字符串解析成一个对象，它拥有以下属性： href - 保存了完整的url地址。要特别注意的是它会将协议以及域名中的大写字母转成小写字母，至于其它位置的字符则会保持原样。这是因为协议以及域名是大小写不分的，为了方便直接全部都转成小写。 protocol - 小写字母组成的协议类型，比如http:。要特别注意:也是协议的一部份（一直觉得很囧）。 slashes - 一个布尔值，一般是true，它注明url的协议后边是否拥有两个/字符，有些奇葩URL是不带//的。 host - 小写字母组成的域名+端口，二者之间有个冒号隔开。如果直接使用IP访问，那么host值就是IP地址，否则就是域名。另外，如果URL上没有写端口那么这里的值跟hostname一致。举个例子：www.host.com:8080。 auth - URL中附带的认证信息，这个很少使用，毕竟不是很安全。当我们访问一个要求认证的网页时，服务器将会返回http状态码401要求浏览器提供用户认证信息，输入用户名和密码之后它将会在Http请求报文头中以Base64的方式写在Authorization字段中。你也可以使用类似”http://user:pass/host.com/a.php&quot;的方式直接将用户名和密码（密码可省略，照样弹出窗口让你输入）写在URL中。 hostname - 域名，跟host不同的是它不带端口。 port - 端口，如果没有该值会使用该协议默认端口，比如http(80)、https(443)、ftp(21)、sftp(22)。 pathname - 请求路径名，它不包含search以及hash。 search - 查询字符串，在URL表现为类似”?id=1”这种形式，要特别注意的是它包含问号(?)。 path - 请求路径，它包含pathname以及search部份，比如”/a/b/c.php?id=1”。许多浏览器并不把URL上的hash部份带到服务器，hash部份一般用于标识本页的某个锚点，因此path这一块是会被附在请求头上送到服务器端。 query - 查询参数，它与search不同之处在于它不带问号，比如”id=1&amp;name=2”。要特别注意的是，使用url.parse解析一个url的时候可以通过设置参数来决定是否对search做解析，如果将parseQueryString参数设置为true，query将会是一个对象，它用键值对的方式保存了search里包含的数据，比如{ id: 1, name: 2 } hash - 锚点，在URL处于末尾，由#号开始。在平时的网页URL中，浏览器一般不会将其发送到服务器端，它更多的是用在客户端。本意是用于做锚点，可以跳到页面某个特定位置，实际上现在更多的是用来做单页面的路由功能。举例：”#hash”。 以下是一个完整的URL对象： 123456789101112131415var urlObject = &#123; href: "http://user:pass@host.com:8080/p/a/t/h?query=string#hash", protocol: "http:", slashes: true, auth: 'user:pass', host: 'host.com:8080', port: '8080', hostname: 'host.com', hash: '#hash', search: '?query=string', query: &#123; query: 'string' &#125;, // 或者 "query=string" pathname: '/p/a/t/h', path: '/p/a/t/h?query=string', href: 'http://user:pass@host.com:8080/p/a/t/h?query=string#hash'&#125; URL模块APIURL模块仅提供了3个函数，没有提供类或者其它东西： url.format - 将一个包含必要字段的urlObject格式化成一个合法的URL字符串。 url.parse - 将一个合法的URL字符串转成urlObject，注意URL并不需要包含所有的字段，比如”./“也算是一个URL字符串。 url.resolve - 拥有from以及to两个参数，自动计算出to相对于from的绝对地址。如果from参数省略，则是将to转换为绝对路径。 这三个函数除了url.resolve都比较容易理解，至于resolve，手册给出了相应的例子，也比较形象： 123url.resolve('/one/two/three', 'four') // '/one/two/four'url.resolve('http://example.com/', '/one') // 'http://example.com/one'url.resolve('http://example.com/one', '/two') // 'http://example.com/two' 小贴士 弄清绝对路径的根目录在哪 在构建一个页面时为了方便可能会使用绝对路径，绝对路径是以/开头的路径，对绝对路径不大了解的前端可能会就发现直接在服务器上查看HTML文件时正常，但直接双击打开html文件则发生路径错误。这时需要认清这绝对路径的根目录到底是哪里。 假设我们的站点放在/wwwroot/mysite，访问地址是http://mysite.com，现在我们需要访问/index.html，它引用了一个路径为/css/site.css的样式文件，它被存放在/wwwroot/mysite/css/site.css。 这时候访问http://mysite.com/index.html，样式能够正常显示，而直接打开/wwwroot/mysite/index.html，则会说找不到/css/site.css。 这是因为在使用域名访问index.html时，绝对路径是指http://mysite.com/，映射到磁盘上的地址是/wwwroot/mysite/，而直接打开index.html时，index.html的地址是/wwwroot/mysite/index.html，这时候的绝对路径根目录是/，这时候磁盘上的/css/site.css是不存在的，真正的地址应该是/wwwroot/mysite/css/mysite.css。 查询字符串的编码 请求一个URL时许多人弄不清哪里需要编码哪里不需要编码，甚至还重复编码，这里特地做一下说明。另外，服务器端接收到你的值是不需要解码的，因为服务器本身就会帮你解码了。 12345678910// 在发起请求的时候，queryString每个字段以及它的值都应该被编码，比如"/file?键1=值1&amp;键2=值2"应该这么写（也可以使用encodeURI，但url不能带search和hash部份）： var url = "/file?" + encodeURIComponent("键1") + "=" + encodeURIComponent("值1") + "&amp;" + encodeURIComponent("键2") + "=" + encodeURIComponent("值2");// 当然，如果你确认你的key和value都不会有非ASCII字符以及需要转义的字符，你也可以不编码（如果不知道是否需要编码，一定要编码，有利无害）。另外，如果值是一个url,该url也需要做编码： // value本身是一个url，请对它的key和value编码。由于key的值是"key"，我确认它绝对不需要编码（因为encodeURIComponent("key")值同样是key），所以我就省掉了。var value = "http://www.site.com/?key=" + encodeURIComponent("这是中文值");// url的值为value的值，value的值也需要编码。var url = "http://mysite.com/?url=" + encodeURIComponent(value);]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Node.js - path模块]]></title>
      <url>%2Farchivers%2F2016%2F11%2Fnode-path%2F</url>
      <content type="text"><![CDATA[Node.js提供了一组非常方便的API专门用来操作路径。不过当你翻开Node.js手册关于path模块的时候，开头那个大大的章节标题”Windows vs. POSIX“呈现在你的面前，不知道你是什么感觉？反正我是觉得蛋疼乳酸菊花紧，兼容问题到哪都逃不掉啊！ Win32以及类Unix的POSIX标准在路径上真心差距很大，这个只要玩过windows以及类Unix系统的人都知道，许多代码由于路径兼容问题直接无法跨平台使用。 不同平台的路径差异路径格式在大多数平台上都是POSIX标准格式，文件系统的根目录为/，然后各种设备（包括多个磁盘也一样）以它为根目录挂载为某个路径，因此任何目录在整个文件系统中的绝对路径都是一致的。 Windows与POSIX不同，它将磁盘分为多个区，它们并没有一个统一的根目录，比如C盘的根目录是C:\，D盘的根目录是D:\，如果你在D盘使用了/来代表根目录，那么它指的就是D:\。 Windows与POSIX在文件、目录名的命名上也略有不同，早期FAT16系统采用的是8.3命名方式，文件名最多8个字符，再加一个.以及最多3个字符的扩展名，比如”filename.ext”，后来win95开始才开始有了长文件名，但也是问题很多。不过我们现在基本上不需要关注短文件名以及长文件名，需要特别关注的是路径分隔符。在Windows的路径中分隔一个目录或文件的采用了\，而POSIX采用的是/，事实上Windows同样认识/分隔符（我宁愿它干脆不认识，净给人添麻烦）。 或许许多前端工程师没关注过什么叫POSIX，简单来说类Unix的系统（linux、BSD、OSX、Unix……）都是遵守POSIX规范的，这里引用一下百度百科对其做说明： POSIX表示可移植操作系统接口（Portable Operating System Interface ，缩写为 POSIX ），POSIX标准定义了操作系统应该为应用程序提供的接口标准，是IEEE为要在各种UNIX操作系统上运行的软件而定义的一系列API标准的总称，其正式称呼为IEEE 1003，而国际标准名称为ISO/IEC 9945。POSIX标准意在期望获得源代码级别的软件可移植性。换句话说，为一个POSIX兼容的操作系统编写的程序，应该可以在任何其它的POSIX操作系统（即使是来自另一个厂商）上编译执行。POSIX 并不局限于 UNIX。许多其它的操作系统，例如 DEC OpenVMS 支持 POSIX 标准，尤其是 IEEE Std. 1003.1-1990（1995 年修订）或 POSIX.1，POSIX.1 提供了源代码级别的 C 语言应用编程接口（API）给操作系统的服务程序，例如读写文件。POSIX.1 已经被国际标准化组织（International Standards Organization，ISO）所接受，被命名为 ISO/IEC 9945-1:1990 标准。 编写一个路径在POSIX和Windows下可以分别这么写： 12var winUrl = "d:\\wwwroot\\site\\file.ext";var posixUrl = "/wwwroot/site/file.ext"; posixUrl在windows下同样认识，但它的位置取决于file.ext文件在哪个分区，如果它在C盘，那么它就相当于”c:\wwwroot\site\file.ext”，如果在其它盘就得换盘符。 为了处理这类不同路径规范，path模块提供了两种实现： path.win32 - 强制使用windows的路径规范处理路径 path.posix - 强制使用posix的路径规范处理路径，根据我的实验，貌似这就是默认的处理方式。 path模块的方法Node.js的path模块针对上述路径差异也提供了相应的API或属性，个人认为，尽可能不要使用windows的路径写法。 path.basename(path[, ext])basename函数可以把路径最后一部份的名字返回，同时你如果使用了扩展名参数，它将自动将扩展名去掉，仅返回文件名（如果最后一部份是文件名的话）。 这里需要注意的是路径最后一部份是否必须是文件，如果是目录怎么办？请看示例代码： 1234567891011121314151617181920var path = require("path");var url = "/wwwroot/site/myfile.js";// myfile.jsconsole.log(path.basename(url));// myfile，要特别注意的是：扩展名包含这个"."，如果仅传"js"的话，将得到"myfile."！console.log(path.basename(url, ".js"));// myfile到底是目录还是文件？url = "/wwwroot/site/myfile";// myfile，可见在这种情况下，它确实不在乎console.log(path.basename(url));// 如果路径最后一部份还带了个/呢？url = "/wwwroot/site/myfile/";// 同样是myfile！这点要特别注意！console.log(path.basename(url)); 之前提到过windows以及POSIX的区别，那么如果路径是一个windows路径，它又是如何工作的？ 1234var url = "E:\\wwwroot\\mysite\\myfile.js";// 将得到 E:\wwwroot\mysite\myfile.jsconsole.log(path.basename(url)); 从运行结果可见，API默认是使用了POSIX，这也难怪，微软本来就是喜欢出一些东西自己玩，不受人待见很正常，但如果你确认你的路径是windows的路径格式，可以使用path.win32提供的同名API： 1234var url = "E:\\wwwroot\\mysite\\myfile.js";// 将得到 myfile.jsconsole.log(path.win32.basename(url)); path.dirname(path)获取指定路径的目录名，它默认将basename当成文件名处理，也就是获取除了路径最后一部份之前的那一段路径。 与basename有个同样的疑问，如果路径最后一个字符是/，也就是路径最后一部份其实也是目录名，那又该怎么样?继续试验： 1234567891011121314151617var path = require("path");var url = "/wwwroot/site/myfile.js";// /wwwroot/site 没什么奇怪的，唯一要注意的是最后不带/console.log(path.dirname(url));// 看看没扩展名的情况url = "/wwwroot/site/myfile";// /wwwroot/site 它不在乎你有没有扩展名console.log(path.dirname(url));// 看看site本身也是目录的情况url = "/wwwroot/site/";// /wwwroot 看来它不在乎最后是不是文件，如果最后一段是目录名，那么它就获取该目录所在的目录路径。console.log(path.dirname(url)); path.extname(path)获取路径的扩展名。 关于扩展名，其实在类Unix系统中，扩展名并不重要，比如你给一个文件加上可执行权限，那么它就会被认为是一个应用程序。如果你用GUI界面操作系统，扩展名的主要工作用于确定mime-type（当然可以造假），然后决定用什么应用程序来打开这个文件。 扩展名是文件名后半部份，它的内容包含”.”，比如myfile.txt的扩展名是”.txt”。 官方给的例子挺详细，直接上： 1234567891011121314path.extname('index.html')// returns '.html'path.extname('index.coffee.md')// returns '.md'path.extname('index.')// returns '.'path.extname('index')// returns ''path.extname('.index')// returns '' 这个要特别注意一下！扩展名可以没有，但文件名不能省。 很幸福的，这个函数在windows系统下表现与POSIX一致。 path.format(pathObject)格式化一个pathObject，将其转成一个合法的字符串。pathObject可以拥有以下属性： dir - 目录路径，这个路径最后不要带有/，否则会出现使用//来分隔目录的情况 root - 根目录 base - 文件名+扩展名 name - 文件名 ext - 扩展名 从手册描述上来看，格式化函数其实是个很弱智的函数，它仅仅是按一个简单的规则将这个pathObject定义的各个属性拼装起来成为一个字符串罢了，基本上遵守以下规则： path分为两个部份，一个是路径，对应dir以及root。一个是文件名，对应base、name以及ext。 dir/root是互斥的，如果dir存在，则不会管root，路径部份以dir为准。 base与name+ext是互斥的，如果base存在，则无视name以及ext，以base为准，也就是说base等于name+ext。 为了更好的了解这个规则，继续上代码： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071var path = require("path");// 文件名为file.txt，dir和root同时存在var pathObject = &#123; dir: ".", root: "/", base: "file.txt"&#125;// ./file.txt root被无视，结果等于dir + "/" + baseconsole.log(path.format(pathObject));// 文件名为file.txt，只存在rootpathObject = &#123; root: "/", base: "file.txt"&#125;// /file.txt 结果等于root + baseconsole.log(path.format(pathObject));// 这里引出了一个疑问，根据上一次输出的结果，// format不会给root和base之间添加/，那么如果root不是/，并且不以/结束会怎么样?// 文件名为file.txt，只存在root，并且值为/wwwroot，它不以/结束pathObject = &#123; root: "/wwwroot", base: "file.txt"&#125;// /wwwrootfile.txt 囧啊，结果真的等于root + base，我早说它不智能了console.log(path.format(pathObject));// 同样，dir注明它被添到结果时，会在后边跟一个/隔开文件名// 文件名为file.txt，只存在dir，并且值以/结尾pathObject = &#123; dir: "/wwwroot/", base: "file.txt"&#125;// /wwwroot//file.txt 只能微笑一下了console.log(path.format(pathObject));// 我们如果故意把base的值瞎搞，它不是一个文件名，而是一段路径，会怎么样？// 文件名为/dir/file.txt，root为/wwwroot，我怀疑结果将是/wwwroot/dir/file.txtpathObject = &#123; root: "/wwwroot", base: "/dir/file.txt"&#125;// /wwwroot/dir/file.txt 如我所料console.log(path.format(pathObject));// 如果dir存在相对路径呢？比如/wwwroot/dir/..相当于/wwwroot，那么是否会处理？pathObject = &#123; dir: "/wwwroot/dir/..", base: "file.txt"&#125;// /wwwroot/dir/../file.txt 真的仅仅是拼接一下，其实这事我也能干啊console.log(path.format(pathObject));// base与name和ext同时存在的情况pathObject = &#123; dir: "/wwwroot", base: "file.txt", name: "myfile", ext: ".js"&#125;// /wwwroot/file.txt 以base为准，name和ext被无视掉了，其它规则跟dir/root一样狗血。console.log(path.format(pathObject)); 虽然path.format是如此弱智，但还是有办法补救的，我们还有一个path.normalize可以用来对它做处理。 path.isAbsolute(path)判断路径是否为绝对路径，这里同样存在兼容问题，由于API默认以POSIX标准为准，因此如果路径是一个windows规范路径，那么需要使用path.win32.isAbsolute来做判断，所以千万不要随便使用windows规范的路径。 12345678910111213var path = require("path");// POSIXvar url = "/wwwroot/dir";// trueconsole.log(path.isAbsolute(url));// WINurl = "E:\\wwwroot";// falseconsole.log(path.isAbsolute(url));// trueconsole.log(path.win32.isAbsolute(url)); path.join([…paths])将多个路径连接在一起，它相对于path.format来说非常智能，你不用担心它生成的路径会出现”//“，也不用担心各种弱智的表现，唯一要考虑的是你输入的路径应该是个字符串。 没什么特别注意的，只需要知道它很智能，能够识别.以及..之类的相对路径，并且把它们拼装成一个很好的路径即可。这是来自官方手册的例子： 12345path.join('/foo', 'bar', 'baz/asdf', 'quux', '..')// returns '/foo/bar/baz/asdf'path.join('foo', &#123;&#125;, 'bar')// throws TypeError: Arguments to path.join must be strings path.normalize(path)在体验过path.format之后，我们需要一个函数对它生成的可能乱七八糟的路径做整理，使其变成一个很规范没有冗余字符的路径，path.normalize就是一个很好的选择。它能够识别.以及..，同时也能够帮你去除多余的/，有点不足的是它不识别windows路径分隔符\。 如果你使用的是win32的normalize，它将会把所有的/转化成\。建议在做处理之前先手工做一下替换，将\统一转成/。 12345678910111213var path = require("path");// 乱七八糟的路径var url = "/wwwroot\\dir0/dir1//.././myfile.txt";// /wwwroot\dir0/myfile.txtconsole.log(path.normalize(url));// \wwwroot\dir0\myfile.txtconsole.log(path.win32.normalize(url));// /wwwroot/dir0/myfile.txt 正解！console.log(path.normalize(url.replace(/\\/g, "/"))); path.parse(path)将一个合法路径解析成一个pathObject，格式参考format函数。这个方法同样不怎么智能，建议使用它的时候先做一下处理（请参考path.normalize示例代码）。 下面来看看它工作表现： 1234567891011121314151617181920212223242526272829303132333435363738394041var path = require("path");// 乱七八糟的路径var url = "/wwwroot\\dir0/dir1//.././myfile.txt";// &#123;// root: '/',// dir: '/wwwroot\\dir0/dir1//../.',// base: 'myfile.txt',// ext: '.txt',// name: 'myfile'// &#125;console.log(path.parse(url));// &#123;// root: '/',// dir: '/wwwroot\\dir0/dir1//../.',// base: 'myfile.txt',// ext: '.txt',// name: 'myfile'// &#125;console.log(path.win32.parse(url));// &#123;// root: '/',// dir: '/wwwroot/dir0/dir1//../.',// base: 'myfile.txt',// ext: '.txt',// name: 'myfile'// &#125;console.log(path.parse(url.replace(/\\/g, "/")));// 正解！// &#123;// root: '/',// dir: '/wwwroot/dir0',// base: 'myfile.txt',// ext: '.txt',// name: 'myfile'// &#125;console.log(path.parse(path.normalize(url.replace(/\\/g, "/")))); path.relative(from, to)获取to参数相对于from参数的相对路径。 这个函数没什么特别好注意的，只需要注意它同样有windows的兼容性问题即可。 以下是官方示例： 12path.relative('/data/orandea/test/aaa', '/data/orandea/impl/bbb')// returns '../../impl/bbb' path.resolve([…paths])这个函数与path.join非常相似，但它将会得到一个绝对路径，并且该路径是基于磁盘文件系统的，得到的结果与当前工作目录有关。 假设我当前工作目录在/wwwroot/github/bennyzheng.github.io/_posts/2016/（是真的……我的测试脚本就放在这个目录），那么以下代码将会得到相应的结果： 12345678var path = require("path");// /wwwroot/github/bennyzheng.github.io/_posts/2016/myfileconsole.log(path.resolve("./", "myfile"));// 注意第二个参数是以/开头，前边的./dir直接被无视掉了，因为它这里已经直接确定好根目录了// /myfileconsole.log(path.resolve("./dir", "/myfile")); path模块的属性path.delimiter保存了当前系统下多个路径的分隔符，它的值在windows系统下是;，在POSIX规范的系统下是:。如果不理解，请查看当前系统的系统变量PATH的值，它就是多个路径连接在一起的。 上一下官方手册的示例代码，它演示了如何利用该属性将系统变量PATH分隔成多个路径，示例中的PATH变量明显是POSIX风格： 12345console.log(process.env.PATH)// '/usr/bin:/bin:/usr/sbin:/sbin:/usr/local/bin'process.env.PATH.split(path.delimiter)// returns ['/usr/bin', '/bin', '/usr/sbin', '/sbin', '/usr/local/bin'] path.sep保存了当前系统下使用的目录分隔符，它的值在windows下是\，在POSIX规范的系统下是/。 path.posix提供了一套针对遵守posix规范的系统的API支持，从目前的试验来看，我们完全可以使用path.xxx来调用API，因为path.posix就是默认的方式。 path.win32提供了一套针对windows系统的API支持，考虑到可移植性，强烈建议不要在你的程序中使用。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Node.js - 探索数据流]]></title>
      <url>%2Farchivers%2F2016%2F11%2Fexplore-data-stream%2F</url>
      <content type="text"><![CDATA[近期一位同事问起数据流方面的问题，在做前端开发时很少直接面对数据流，只有在做node.js相关的东西会接触得比较多。我当时简单做了一些解答，但我认为我解答得不是很好，至少她还是一脸的迷茫。于是我准备在这里试着讲清数据流的来龙去脉。 认识数据流数据流是数据操作的抽象，它以统一的API、高效的内部实现让数据操作者很方便地操作多种设备上的数据，简单一点可以把数据流当成一组操作数据的API。 数据流并不是一个新概念，Unix系统将很多硬件设备挂载成设备文件，然后提供了一组低级I/O API用于数据交换，如果学过C语言那么这组API肯定会非常熟悉，许多数据(不仅仅是磁盘文件)的读写都可以用它们来做： 1234int open(const char *path, int oflag, ...);ssize_t read(int fildes, void *buf, size_t nbyte);ssize_t write(int fildes, const void *buf, size_t nbyte);int close(int fildes); 可以看出Unix在数据读写方面已经考虑到了API的统一，这组I/O API被称为低级I/O，它们直接使用了系统调用来直接访问硬件进行数据读写，而且还不带缓冲区，这意味着每次调用都将读写一次设备，频繁的读写不仅存在性能问题还会影响到设备的寿命，大家在写C程序的时候一般使用的是标准I/O API： 1234FILE *fopen(const char *restrict filename, const char *restrict mode);size_t fread(void *restrict ptr, size_t size, size_t nitems, FILE *restrict stream);size_t fwrite(const void *restrict ptr, size_t size, size_t nitems, FILE *restrict stream);int fclose(FILE *stream); 标准I/O的底层实现依然是调用了低级I/O，并且在低级I/O上再做了一层封装，实现了缓冲区，允许数据预读、缓写等缓冲功能，减少了与设备打交道的次数，也提高了性能。请注意标准I/O的原型声明，FILE *类型的变量被命名为stream。由于C不是面向对象的，File *stream代表着数据，加上配套的标准I/O共同组成了数据流。数据流对原始数据操作做了一层封装，使其更合理、高效并且拥有了统一的API。 数据流的使用Java语言给流抽象了四种类型: InputStream - 二进制输入流，应用程序可以使用该流从某个数据设备读取二进制数据 OutputStream - 二进制输出流，应用程序可以使用它往某个数据设备写入二进制数据 Reader - 字符输入流，与InputStream不同的是它操作的是字符串 Writer - 字符输出流，与OutputStream不同的是它写入的是字符串 事实上，Reader和Write看起来更像是InputStream、OutputStream的一种封装，二者仅仅操作的是数据类型不一样，字符串也同样是二进制的。 而我们熟悉的Node.js同样给流抽象了四种类型： Readable - 拥有读能力的数据流 Writable - 拥有写能力的数据流 Duplex - 双向流，是Readable以及Writable的合体 Transform - 对Duplex的封装，允许写入数据后对数据做修改，重新读出来的数据将是修改后的数据 从Java以及Node.js对流的定义上来看，数据流并没有一个固定的形式，但不外乎用于读和写，并且根据实际场景流可以同时拥有读和写的功能。数据流将数据使用者与数据设备隔离开来，数据使用者不需要关心数据设备接口是如何工作的，只需要调用数据流提供的统一的API即可完成操作。 对于一名前端工程师来说弄懂Node.js的数据流帮助更大，以下就以Node.js的数据流来做一些实验。 Readablefs模块提供了文件读写功能，其中有一个方法readFileSync非常方便，它可以一次性把文件内容返回给应用程序，示例代码如下： 123456var fs = require("fs");var content = fs.readFileSync("./test.js", &#123; "encoding": "utf-8", "flag": "r"&#125;);console.log(content); 看起来非常方便，但对于小文件可以这样，对于大文件（比如动不动就上G的视频文件）如果还这么做分分钟内存溢出。 换种做法可以解决这种问题，比如使用fs.open/fs.read，但使用数据流是最简单的方法。 Readable以及其它数据流是以事件驱动来与应用程序互动的，它提供了以下几个事件： close - 流关闭时分发close事件，当一个流被关闭之后就不再生产数据，即变成不可读状态。手册中提示并不是所有的只读流都会分发该事件，它没有任何参数。 data - 在缓冲区有数据时分发data事件，拥有一个chunk参数。当data事件分发时，chunk参数默认会得到一个对象，如果数据源提供的是字符串数据，则可以通过setEncoding函数设置文本编码，这时候chunk将会是一个字符串。 end - 当数据源不再生产数据时（比如磁盘文件读到结尾）分布本事件。 error - 当操作发生错误时触发。 readable - 当缓冲区有数据时分发readable事件，但需要主动调用read([size])函数读取数据。 除了事件还提供了以下方法： isPaused - 检测流是否处于暂停状态，只有显式调用了pause方法才会让流转入暂停状态，不再从数据源读取数据。 pause - 显式要求流转入暂停状态，在暂停状态下不再从数据源读取数据，也不会触发data、readable事件。 pipe - 非常重要的方法，它能够传入一个允许写入的流（除了Readable，其它流都允许写入）当作流数据的目的地，成为一个管道。Readable将会自动读取数据，并且将它写入Writable流中。 read - 主动从数据缓冲区读取数据，可以显式传入size参数要求读多少字节，如果不传则是读取缓冲区全部数据。 resume - 显式要求流从暂停状态转入流动状态。 setEncoding - 如果确认数据源是字符串，那么可以使用setEncoding方法设置文本编码。要注意的是如果设置了文本编码，那么data事件的chunk参数或者read方法都将返回String而不是Buffer。 unpipe - 将管道断掉，pipe的反操作。 unshift - 将数据块重新塞回缓冲区，可以对数据块做修改。参考手册提示如果有这类需求应该考虑使用Transform流，个人觉得也确实如此，如果使用这个函数就失去了只读的意义了。 wrap - 允许传入一个旧数据流的实现，将它做为数据源使用新的流API读取。Node.js在之前有一套旧的流实现，这主要是做代码兼容之用。 push - 将数据添加到Readable的数据缓冲区，这个函数是为扩展Readable而实现的，除非你实现Readable的子类，否则它不应该被使用。 一个刚打开的Readable流默认处于流动状态，调用isPaused函数可以看到值确实为false，但网上许多资料说刚打开的Readable是处于暂停状态，要绑定data、调用resume函数之类的操作才会让流进入流动状态。经过试验，在流刚打开时，stream._readableState.flowing的值为null，绑定data事件后会变成true，调用pause函数后变回false。也就是说相当于暂停状态，这么看就合理了，它确实不是暂停状态（值不是false），但也同时不是流动状态，但可以把这种默认状态当成暂停状态处理。 EventEmitter类是Node.js实现事件模型的基类，所有数据流都是它的子类，数据流的读操作也基本上是靠事件来工作。读操作一般是使用data+end或者readable+end事件来完成，或许在这里会有疑问为什么会提供了如此相似的两个事件。 data事件会将缓冲区第一个Buffer对象作为参数传给事件响应函数，如果使用了setEncoding方法设置了文本编码它将会将Buffer对象转成字符串作为参数，这是Readable主动取出数据交给响应函数。readable事件与data事件不同，readable仅仅是在数据缓冲区有数据可读时调用响应函数，然后由应用程序自己主动去调用read读取数据。 data事件以及pipe方法优先级会比readable事件更高，如果绑定了data事件或者调用pipe方法建立了数据管道，在这种情况下每次读取到数据的时候会触发data事件，但在所有数据都读取完之后会触发一次readable，并且调用read方法会得到null。 如果仅仅是将数据读到内存那么使用data事件妥妥的很方便，如果数据将会被写入到磁盘或者其它写入速度可能比读取速度慢的设备时则需要特别考虑到读写速度不同导致的问题，必须等到数据写完才能够读下一个缓冲区的数据。data事件可以将数据块chunk交给应用程序，应用程序得到chunk之后直接调用pause函数暂停流的读取，然后异步写入数据，在写完数据后再显式调用resume函数重新让流开始读取数据。而readable事件则可以由应用程序决定一次读多少数据到应用程序自己管理的缓冲区（其实就是内存中的一个变量），同样暂停流写入数据再恢复数据流的流动。也就是说readable看起来麻烦了一点，但灵活性更高，毕竟用户可以决定读多少数据。 以下是读取一个文件的例子： 12345678910111213var fs = require("fs");var stream = fs.createReadStream("./test.js");var content = "";stream.setEncoding("utf-8");stream.on("data", function(chunk) &#123; content += chunk;&#125;);stream.on("end", function() &#123; console.log("content"); stream.close();&#125;); 在该例子中，首先使用了setEncoding设置该文件为文本文件，并且编码是utf-8。data事件不断触发，将数据追加到内存中，在end的时候关闭流，这是最普通的文件读取例子。 同样，可以使用readable来实现同样的功能： 1234567891011121314151617var fs = require("fs");var stream = fs.createReadStream("./test.js");var content = "";stream.setEncoding("utf-8");stream.on("readable", function() &#123; var buffer = this.read(); if (buffer != null) &#123; content += buffer; &#125;&#125;);stream.on("end", function() &#123; console.log(content); stream.close();&#125;); 这里要特别注意一点，readable在读到文件结尾的时候，还会触发一次，并且调用read函数读到的数据为null，所以要判断一下。在手册中特别提到，read函数应该仅在流处于暂停状态下才被调用，但在上边的示例中并没有显式调用pause方法将流暂停，流的状态值默认是null。如果手动在绑定readable事件之前调用resume，那么在事件响应中调用read方法将会得到null值，因为读取的数据块已经通过data事件分发出去了，哪怕你没监听data事件。 在以下示例中读取一个简单的js文件，read方法将得到null。 1234567891011121314var fs = require("fs");var stream = fs.createReadStream("./test.js");stream.setEncoding("utf-8");stream.resume();stream.on("readable", function () &#123; // false true null console.log(this.isPaused(), this._readableState.flowing, this.read());&#125;);stream.on("end", function() &#123; stream.close();&#125;); 之前提到过写的速度没有读的速度快时，我们需要对Readable流读取的速度进行限制，由于尚未讲到Writable流，因此直接使用fs.appendFile来实现： 123456789101112131415var fs = require("fs");var stream = fs.createReadStream("./test.js");stream.setEncoding("utf-8");stream.on("data", function ondata(chunk) &#123; stream.pause(); fs.appendFile("./test.dist.js", chunk, function() &#123; stream.resume(); &#125;);&#125;);stream.on("end", function() &#123; stream.close();&#125;); fs.appendFile是个异步操作，在触发data事件的时候先让数据流暂停（这时候不再触发data事件），然后开始异步写数据，写完数据调用resume让数据流重新开始流动。 WritableWritable流允许向一个数据设备写入数据，它拥有以下事件： close - 数据流关闭时触发，数据流关闭后就不能向其写入数据。 drain - 数据流缓冲区数据量达到高水位（highWaterMark）后需要暂停往Writable写入数据，Writable缓过劲来的时候将会触发本事件，通知外部可以继续往数据流里写数据。 error - 数据流写入数据失败或者其它错误时触发该事件。 finish - 当数据流被调用了end方法之后触发，这时候所有数据已经从缓冲区写入数据设备。 pipe - 如果本Writable流被当成参数传入某个Readable流作为数据管道的下游时，Readable往Writable写入数据时将会触发本事件，表示管道有数据流入。 unpipe - Readable断开与Writable的管道关系时触发 以下是Writable提供的方法 cork - 塞住数据流与数据设备的数据交换，这时候所有写入Writable的数据将被存放到缓冲区，除非调用了uncork或者end方法才会将缓冲区的数据写入数据设备。 end - 要求数据流清空缓冲区，将所有数据全部写入数据设备。调用该方法后就不允许再使用write方法写入数据。 setDefaultEncoding - 当数据来源是文本数据时可以为其设置一个默认的编码，如果没有设备过则表示数据是Buffer形式。 uncork - cork的反操作，允许数据流重新开始将保存在缓冲区的数据写入数据设备。 write - 往数据流写入数据，数据可能会马上被写入数据设备，也可能保存到缓冲区 Writable跟Readable在使用上略有不同，Readable基本上通过监听data或readable事件来被动获取数据，而Writable则是反过来被动地被调用write方法写入数据。 一个最简单的写数据例子如下： 12345678var fs = require("fs");var stream = fs.createWriteStream("./test.dist.js");stream.setDefaultEncoding("utf-8");stream.write("hello world");stream.on("end", function() &#123; stream.close();&#125;); 外部向数据流写入数据的速度如果比数据流写入数据设备的速度快时，来不及写入的数据将会被放到缓冲区。缓冲区有一个名为高水位（highWaterMark）的限制，如果数据流是对象模式（二进制，数据以Buffer存放）则默认是16个Buffer对象，如果是文本模式（数据以String的形式存放）则默认是16kb。当超过缓冲区高水位时，写入的数据依然会被放到缓冲区，但这时候write方法将会返回false，通知写入者必须缓一缓了。暂停写入数据后，Writable会继续往数据设备写数据，在缓冲区的数据清空后将会分发drain事件，通知写入者可以继续调用write写数据。 使用drain事件可以将Readable中对应的例子简单改改： 123456789101112131415161718192021var fs = require("fs");var stream = fs.createReadStream("./test.js");var wstream = fs.createWriteStream("./test.dist.js");stream.setEncoding("utf-8");wstream.setDefaultEncoding("utf-8");stream.on("data", function(chunk) &#123; if (!wstream.write(chunk)) &#123; this.pause(); &#125; &#125;);stream.on("drain", function() &#123; this.resume();&#125;);stream.on("end", function() &#123; this.close(); wstream.close();&#125;); 事实上还有更好的办法可以处理这种情况，比如直接使用Readable的pipe方法让Readable与Writable配对形成管道，Readable读出来的数据会直接写入Writable，同时它会处理好各种情况而不需要工程师自己操心，从这方面上看，pipe简直就是节省代码的神器： 1234567var fs = require("fs");var stream = fs.createReadStream("./test.js");var wstream = fs.createWriteStream("./test.dist.js");stream.setEncoding("utf-8");wstream.setDefaultEncoding("utf-8");stream.pipe(wstream); Duplex &amp; Transform看了Node.js关于双向流的手册，里边介绍非常简单，双向流是Readable和Writable的合体，也就是说我们可以把它当Readable使用也可以当Writable使用，二者有的事件与方法双向流也都有，因此在这里不再重复说明。 双向流要特别注意的一点就是：它既然是Readable和Writable的合体，因此它可以利用pipe形成一个管道链，最简单的就是对数据做压缩并且输出到一个文件中： 12345678var fs = require("fs");var zlib = require("zlib");var gz = zlib.createGzip();var stream = fs.createReadStream("./test.js");var wstream = fs.createWriteStream("./test.js.gz");stream.setEncoding("utf-8");stream.pipe(gz).pipe(wstream); 示例中，gz对象是zlib创建的一个Transform流，它的工作就是外部写入数据，然后它对其做压缩处理后输出给wstream写入文件中，这种方式在gulp脚本中应用非常多。 数据流的扩展四种数据流都是基类，类似fs.createReadStream返回的数据流其实都是它们的子类。要实现自己的数据流，需要继承相应的数据流，并且实现关键方法： Readable: _read Writable: _write, _writev Duplex: _read, _write, _writev Transform: _transform, _flush ReadableReadable可以使用new Readable创建一个子类，并传入这些参数： highWaterMark - 缓冲区高水位限制，当读取的数据放入缓冲区后超过高水位则暂缓读入，直到缓冲区数据被外部读取消耗掉。 encoding - 如果数据源是文本数据，则可以传入编码，将数据流从默认的对象模式转为文本模式，使用read方法或者data事件得到的数据块将使用该编码解码，并且类型都将变成String。 objectMode - 是否使用对象模式，如果值为false则表示数据源是文本数据，将使用默认编码将Buffer转成String。 read - 实现私有方法_read，实现数据流自定义的数据读取方式，该方法由数据流本身调用，不需要考虑缓冲区的问题。 以下是使用new Readable创建一个新的只读数据流的示例： 123456789var fs = require("fs");var util = require("util");var Readable = require("stream").Readable;const FileReadString = new Readable(&#123; read: function(size) &#123; // 在这里实现读取数据的具体实现 &#125;&#125;); 我个人认为使用new Readable方式创建子类的形式很不灵活，更倾向于使用Node.js用于做类型扩展的工具函数util.inherits创建它的了类，以只读文件为例实现如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354var fs = require("fs");var util = require("util");var Readable = require("stream").Readable;function FileReadStream(path, options) &#123; // 必须调用基类的构造函数，将配置信息传进去 Readable.call(this, options); this._path = path; // 文件路径，为了省事，不考虑该文件不存在的情况 this._offset = 0; // 当前文件游标在文件中的位置 this._fd = null; // 文件描述符&#125;util.inherits(FileReadStream, Readable);/*** 重写_read方法* 由于_read应该是一个同步操作，所以这里使用的都是同步API*/FileReadStream.prototype._read = function(size) &#123; // 第一次使用时打开文件 if (this._fd == null) &#123; this._fd = fs.openSync(this._path, "r"); &#125; // 如果不指定需要读多少数据，则默认读16kb。 size = size == null ? 1024 * 16 : size; var buffer = Buffer.alloc(size); var len = fs.readSync(this._fd, buffer, 0, size, this._offset); this._offset += len; if (len == 0) &#123; // 如果读不出数据则调用push(null)告诉数据流已经没有数据了 this.push(null); // 关闭掉文件 fs.closeSync(this._fd); this._fd = 0; // 分发事件，告诉外部数据流已经关闭 this.emit("close"); &#125; else &#123; // 将读取的二进制数据插入到缓冲区，是否转成文本那是Readable自己的事 this.push(buffer); &#125;&#125;var stream = new FileReadStream("./test.js");stream.setEncoding("utf-8");stream.on("data", function(chunk) &#123; console.log(chunk);&#125;); 除了这两个方法，还可以使用es6的extends来扩展，手册中有不再详说。 Writable创建一个Writable的子类可以传入以下参数： highWaterMark - 写缓冲区的高水位，如果写入的数据超出高水位的限制，那么Writable的write方法将会返回false通知外部需要暂停写入，当数据从缓冲区写入到数据设备后将会触发drain事件通知外部可以重新写入数据。 decodeStrings - 要求Writable在写入数据时是否先将Buffer以这里设置的编码转成字符串再调用_write方法。 objectMode - 是否启用对象模式，如果启用写入的数据将是一个Buffer。 _write - 将数据写到数据设备的具体实现。 _writev - 批量写入多个数据，它并不是必须实现的，但可以重写。它的参数跟_write相比（请看下方示例）少了一个encoding，而chunk则换成chunks（数组），每个元素是一个形式为{ chunk: …, encoding: …}的对象，默认是调用_write来完成工作，可以重写它来实现更高效的批量写入。 具体细节不再讲解，以写一个磁盘文件为例实现一个FileWriteStream： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960var fs = require("fs");var util = require("util");var Writable = require("stream").Writable;function FileWriteStream(path, options) &#123; // 必须调用基类的构造函数，将配置信息传进去 Writable.call(this, options); this._path = path; // 文件路径 this._fd = null; // 文件描述符&#125;util.inherits(FileWriteStream, Writable);/** * _write的实现，这里应该使用异步模式写入数据 * @param chunk 数据块，可能是一个Buffer也可能是一个String * @param encoding 当chunk是一个String时，这里注明了它的编码 * @param callback 当写入操作完成时_write需要调用callback通知外部已经写完数据,如果写入发生异常也需要将Error对象传给callback * @private */FileWriteStream.prototype._write = function(chunk, encoding, callback) &#123; var stream = this; function write() &#123; fs.write(stream._fd, chunk, 0, chunk.length, function(err, written, buffer) &#123; if (err != null) &#123; callback(err); return; &#125; callback(); &#125;); &#125; if (this._fd == null) &#123; fs.open(this._path, "a", function(err, fd) &#123; if (err != null) &#123; callback(err); return; &#125; stream._fd = fd; stream.once("end", function() &#123; fs.closeSync(stream._fd); stream._fd = null; &#125;); write(); &#125;); &#125; else &#123; write(); &#125;&#125;var stream = new FileWriteStream("./test.txt");stream.write("hello world");stream.end(); 从这里可以看出Readable跟Writable与数据设备交互的时候略有不同，前者必须用同步读取，因为数据必须马上返回给外部，而Writable则可以异步写数据，因为数据设备的写入速度不可预知，而外部数据是写到缓冲区中的。 DuplexDuplex在手册中一直强调是Readable以及Writable的合体，非常经典的应用就是tcp socket。它的扩展方式是Readable以及Writable二者扩展方式的合并，不过在创建子类的时候参数略有不同，单独出现Duplex的原因是因为Javascript不支持多重继承（囧）。 allowHalfOpen - 是否允许半打开状态，默认为真。Duplex流是双向流，因此跟外部的交互有读有写，如果设置为false，则当其中一个方式结束时自动关闭另一个，默认允许只关闭一端。 readableObjectMode - 当被作为可读流使用时是否使用对象模式 writableObjectMode - 当被作为可写流使用时是否使用对象模式 _read - 实现read方法 _write - 实现write方法 _writev - 实现批量写操作，可以不实现。 这里不再对Duplex的实现做示例，因为仅仅是Readable和Writable实现的合并。 TransformTransform是对Duplex的扩展，它的作用更多是用在数据的处理环节上，工程师调用Transform的write方法写入数据，然后Transform将数据交给_transform做处理，处理完后再写入read的缓冲区允许外部读取，gulp在这方面应用得特别多。 _transform - 对写入的数据做处理，并重新塞回Readable缓冲区以供外部读取 _flush - 将Writable中残留的缓冲区数据交给_transform做处理，本方法可以不实现 以下实现用于去除字符串空格的Transform示例： 12345678910111213141516171819202122232425var fs = require("fs");var util = require("util");var Transform = require("stream").Transform;function StringTransform(options) &#123; Transform.call(this, options);&#125;util.inherits(StringTransform, Transform);StringTransform.prototype._transform = function(chunk, encoding, callback) &#123; var str = chunk.toString("utf-8").replace(/\s/g, ""); this.push(str); callback();&#125;var str = "这 可 是 一 段 文 字 ";var stream = new StringTransform();stream.setEncoding("utf-8");stream.on("data", function(chunk) &#123; console.log(chunk);&#125;);stream.write(str);]]></content>
    </entry>

    
  
  
</search>
